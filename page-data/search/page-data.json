{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"이 글은 우테코 괜찮을지도팀의 이 작성했습니다. 홈페이지에서 용량을 많이 차지하고 페이지 로딩 속도에 영향을 미치는 이미지와 번들 사이즈 최적화를 진행하였습니다. 이미지 최적화 홈페이지에서 가장 많은 용량을 차지하고 페이지 로딩 속도에 가장 큰 영향을 미치는 것은 이미지라는 의견이 나왔습니다. 백엔드 쪽에서는 이미지 업로드 용량 한계치를 두고 프론트 단에…","fields":{"slug":"/how-to-optimize-website/"},"frontmatter":{"date":"October 18, 2023","title":"괜찮을지도 사이트 최적화 진행","tags":["블로그"]},"rawMarkdownBody":"\n> 이 글은 우테코 괜찮을지도팀의 `패트릭`이 작성했습니다.\n\n홈페이지에서 용량을 많이 차지하고 페이지 로딩 속도에 영향을 미치는 이미지와 번들 사이즈 최적화를 진행하였습니다.\n\n## 이미지 최적화\n\n홈페이지에서 가장 많은 용량을 차지하고 페이지 로딩 속도에 가장 큰 영향을 미치는 것은 이미지라는 의견이 나왔습니다. 백엔드 쪽에서는 이미지 업로드 용량 한계치를 두고 프론트 단에서 용량을 줄이기로 하였습니다.\n\n### browser-image-compression 라이브러리 사용\n![Alt text](.index_image/browser-compression.png)\n\n그리고 하나의 이미지와 여러 개의 이미지를 압축하는 곳이 따로 있어 구분해서 적용하기 위해 custom hook으로 분리하였습니다.\n```typescript\nimport imageCompression from 'browser-image-compression';\n\nconst useCompressImage = () => {\n  const compressImage = async (file: File) => {\n    const resizingBlob = await imageCompression(file, {\n      maxSizeMB: 1, // 최대 이미지 용량\n      maxWidthOrHeight: 750, // 최대 이미지 크기\n      useWebWorker: true, // 비동기 처리 유무\n    });\n    const resizingFile = new File([resizingBlob], file.name, {\n      type: file.type,\n    });\n    return resizingFile;\n  };\n\n  const compressImageList = async (files: FileList) => {\n    const compressedImageList: File[] = [];\n\n    for (const file of files) {\n      const compressedImage = await compressImage(file);\n      compressedImageList.push(compressedImage);\n    }\n\n    return compressedImageList;\n  };\n\n  return { compressImage, compressImageList };\n};\n\nexport default useCompressImage;\n```\n\n이를 통해 성능이 개선된 지표입니다.\n![Alt text](.index_image/optimize-compress.png)\n\n\n\n## 번들 사이즈\n이미지 다음으로 번들 사이즈가 페이지 로딩 속도에 영향을 끼친다는 것을 알았습니다. 동적 import(lazy, suspense 이용)와 tree shaking을 통해 개선할 수 있었습니다.\n\n```typescript\nconst SelectedTopic = lazy(() => import('./pages/SelectedTopic'));\nconst NewPin = lazy(() => import('./pages/NewPin'));\nconst NewTopic = lazy(() => import('./pages/NewTopic'));\nconst SeeAllPopularTopics = lazy(() => import('./pages/SeeAllPopularTopics'));\nconst SeeAllNearTopics = lazy(() => import('./pages/SeeAllNearTopics'));\nconst SeeAllLatestTopics = lazy(() => import('./pages/SeeAllLatestTopics'));\nconst KakaoRedirect = lazy(() => import('./pages/KakaoRedirect'));\nconst Profile = lazy(() => import('./pages/Profile'));\nconst AskLogin = lazy(() => import('./pages/AskLogin'));\nconst Bookmark = lazy(() => import('./pages/Bookmark'));\n```\n\n```typescript\n\nfunction SuspenseComp({ children }: SuspenseCompProps) {\n  return <Suspense fallback={null}>{children}</Suspense>;\n}\n\n{\n  path: 'topics/:topicId',\n  element: (\n    <SuspenseComp>\n      <SelectedTopic />\n    </SuspenseComp>\n  ),\n  withAuth: false,\n},\n{\n  path: 'new-topic',\n  element: (\n    <SuspenseComp>\n      <NewTopic />\n    </SuspenseComp>\n  ),\n  withAuth: true,\n},\n{\n  path: 'new-pin',\n  element: (\n    <SuspenseComp>\n      <NewPin />\n    </SuspenseComp>\n  ),\n  withAuth: true,\n},\n{\n  path: 'see-all/popularity',\n  element: (\n    <SuspenseComp>\n      <SeeAllPopularTopics />\n    </SuspenseComp>\n  ),\n  withAuth: false,\n},\n{\n  path: 'see-all/near',\n  element: (\n    <SuspenseComp>\n      <SeeAllNearTopics />\n    </SuspenseComp>\n  ),\n  withAuth: false,\n},\n{\n  path: 'see-all/latest',\n  element: (\n    <SuspenseComp>\n      <SeeAllLatestTopics />\n    </SuspenseComp>\n  ),\n  withAuth: false,\n},\n{\n  path: 'favorite',\n  element: (\n    <SuspenseComp>\n      <Bookmark />\n    </SuspenseComp>\n  ),\n  withAuth: true,\n},\n{\n  path: 'my-page',\n  element: (\n    <SuspenseComp>\n      <Profile />\n    </SuspenseComp>\n  ),\n  withAuth: true,\n},\n{\n  path: '/askLogin',\n  element: (\n    <SuspenseComp>\n      <AskLogin />\n    </SuspenseComp>\n  ),\n  withAuth: false,\n},\n```\n\n\n- 개선 전\n![Alt text](.index_image/before.png)\n\n- 개선 후\n![Alt text](.index_image/after.png)"},{"excerpt":"이 글은 우테코 괜찮을지도팀의 가 작성했습니다. 백엔드 크루 '매튜'와 협력해 S3에 이미지를 저장하는 작업을 진행하였습니다. 생각보다 시간도 오래 걸리고 어려움도 많았지만 많이 배웠고 보람있는 시간이었습니다. 이미지 관련 사용자 피드백 이미지를 string으로 저장하고 있어 이미지를 저장하는데 번거럽다는 피드백을 받았습니다. formData를 통해 이미…","fields":{"slug":"/how-to-store-image-s3/"},"frontmatter":{"date":"October 18, 2023","title":"백엔드와 협력해 S3에 이미지 저장하기","tags":["블로그"]},"rawMarkdownBody":"\n> 이 글은 우테코 괜찮을지도팀의 `패트릭`가 작성했습니다.\n\n백엔드 크루 '매튜'와 협력해 S3에 이미지를 저장하는 작업을 진행하였습니다. 생각보다 시간도 오래 걸리고 어려움도 많았지만 많이 배웠고 보람있는 시간이었습니다.\n\n### 이미지 관련 사용자 피드백 \n이미지를 string으로 저장하고 있어 이미지를 저장하는데 번거럽다는 피드백을 받았습니다.\n\n##  formData를 통해 이미지 서버에 전송하기\n\nfile type의 Input 태그를 만듭니다.<br>\nfile을 서버로 전송하면 해당 file 데이터를 multipart/form-data형태로 받습니다.\n\n```typescript\n<ImageInputButton id=\"file\" type=\"file\" name=\"image\" onChange={onHandler} />\n``` \n\nform 데이터를 동적으로 생성하고 전송 가능한 객체인 formData를 써서 내용을 key와 value 형식으로 보내도록 했습니다.\n\n```typescript\nconst formData = new FormData();\n\nif (formImage) {\n   formData.append('image', formImage);\n}\n``` \n\n### 문제 상황 : 1차 서버 에러 발생\n서버 Post 요청 시 서버쪽에서 아래와 같은 에러가 발생했습니다.\n```java\n// 에러\nCaused by: org.apache.tomcat.util.http.fileupload.FileUploadException: the request was rejected because no multipart boundary was found\nat org.apache.tomcat.util.http.fileupload.impl.FileItemIteratorImpl.init(FileItemIteratorImpl.java:189)\nat org.apache.tomcat.util.http.fileupload.impl.FileItemIteratorImpl.getMultiPartStream(FileItemIteratorImpl.java:205)\nat org.apache.tomcat.util.http.fileupload.impl.FileItemIteratorImpl.findNextItem(FileItemIteratorImpl.java:224)\nat org.apache.tomcat.util.http.fileupload.impl.FileItemIteratorImpl.<init>(FileItemIteratorImpl.java:142)\nat org.apache.tomcat.util.http.fileupload.FileUploadBase.getItemIterator(FileUploadBase.java:252)\nat org.apache.tomcat.util.http.fileupload.FileUploadBase.parseRequest(FileUploadBase.java:276)\nat org.apache.catalina.connector.Request.parseParts(Request.java:2799)\n... 46 common frames omitted\n``` \n\n에러의 원인은 boundary를 찾지 못해 나는 것이었고 formData에 파일이 있을 경우 브라우저는 자동으로 boundary를 붙여준다는 것을 알았습니다. 여기서 Post 요청을 할 때 개발자가 content-type을 multipart/form-data로 지정해주면 브라우저가 자동으로 생성한 boundary를 덮어써 버립니다. 그리고 서버는 요청 본문을 올바르게 파싱하지 못하여 파일 및 폼 데이터를 올바르게 처리하지 못합니다.<br>\n그래서 content-type을 지우면 해결이 될거라고 생각해 지웠습니다. 그러나 역시 문제는 쉽게 해결되지 않는 법! 또 다른 에러가 발생하였습니다.\n\n\n### 문제 상황 : 2차 서버 에러 발생\njson 데이터를 application/json 타입으로 명시해 주지 않아 octet-stream(8비트 단위의 이진 데이터)로 인식하여 발생한 에러였습니다. 'Blob(Binary Large Object)'을 사용하여 해결할 수 있었습니다.\n\n```java\nconst data = JSON.stringify(objectData);\n// Blob처리로 JSON 문자열이 이진 데이터로 변환. 또한 type에 application/json을 명시\nconst jsonBlob = new Blob([data], { type: 'application/json' });\n\nformData.append('request', jsonBlob);\n``` \n\n\n이러한 과정을 통해 서버에 이미지와 데이터를 전송할 수 있었고 이를 바탕으로 S3에 이미지를 저장할 수 있었습니다!"},{"excerpt":"이 글은 우테코 괜찮을지도의 가 작성하였습니다. 서론 간단한 도메인 설명 저희 서비스에는  이라는 도메인이 존재하고, 이는 를 의미합니다. 그리고 해당 는 , ,  들과  를 이루고 있습니다. 문제 발생 상황 문제 상황 이 글에서 주로 탐구하고 있는 문제는 서비스 홍보를 앞두고 성능 개선을 하기 위해  문제를 해결하고 있던 와중 발생하였습니다. 일단 유의…","fields":{"slug":"/set-or-list/"},"frontmatter":{"date":"October 15, 2023","title":"N + 1 문제 해결 도중 맞닥뜨린 Set 과 List 의 차이","tags":["Spring Data JPA","Hibernate"]},"rawMarkdownBody":"\n> 이 글은 우테코 괜찮을지도의 `매튜`가 작성하였습니다.\n\n### 서론\n\n## 간단한 도메인 설명\n\n저희 서비스에는 `Topic` 이라는 도메인이 존재하고, 이는 `지도`를 의미합니다.\n\n그리고 해당 `지도`는 `Permission(권한)`, `Pin(핀)`, `Bookmark(즐겨찾기)` 들과 `1:N` `연관관계`를 이루고 있습니다.\n\n\n## 문제 발생 상황 \n\n### 문제 상황\n\n이 글에서 주로 탐구하고 있는 문제는 서비스 홍보를 앞두고 성능 개선을 하기 위해 `N + 1` 문제를 해결하고 있던 와중 발생하였습니다.\n\n일단 유의미한 성능 차이를 보기 위해, 우선적으로 `Topic` 과 `Pin` 데이터를 각각 `10만개`씩 넣고 진행하였습니다.\n\n또한 요청은 `PostMan` 을 이용하여 테스트 하였습니다.\n\n아래는 그 때의 `코드`입니다.\n\n- Topic\n```java\n@Entity  \n@NoArgsConstructor(access = PROTECTED)  \n@Getter  \npublic class Topic extends BaseTimeEntity {  \n\n\t... 생략\n  \n    @ManyToOne(fetch = FetchType.LAZY)  \n    @JoinColumn(name = \"member_id\")  \n    private Member creator;  \n  \n    @OneToMany(mappedBy = \"topic\")  \n    private List<Permission> permissions = new ArrayList<>();  \n  \n    @OneToMany(mappedBy = \"topic\", cascade = CascadeType.PERSIST)  \n    private List<Pin> pins = new ArrayList<>();  \n  \n    @OneToMany(mappedBy = \"topic\", cascade = CascadeType.PERSIST, orphanRemoval = true)  \n    private List<Bookmark> bookmarks = new ArrayList<>();  \n\n\t... 생략\n\n}\n```\n\n- TopicRepository\n```java\n@Repository  \npublic interface TopicRepository extends JpaRepository<Topic, Long> {  \n\n    @EntityGraph(attributePaths = {\"creator\", \"permissions\", \"bookmarks\", \"pins\"})  \n    List<Topic> findAll();  \n\n}\n```\n\n당연히 위 코드는 `MultipleBagFetchExcepion` 예외가 발생하였습니다. (`MultipleBagFetchExcepion` 자세한 설명은 https://map-befine-official.github.io/jpa-multibag-fetch-exception/ 해당 글을 확인해주세요!)\n\n### MultipleBagFetchExcepion 해결\n\n우리는 해당 예외를 해결하기 위해 `Topic` 의 `Collection` 들의 `자료구조`를 `Set` 으로 바꿔주었습니다.\n\n```java\n@Entity  \n@NoArgsConstructor(access = PROTECTED)  \n@Getter  \npublic class Topic extends BaseTimeEntity {  \n\n\t... 생략\n  \n    @ManyToOne(fetch = FetchType.LAZY)  \n    @JoinColumn(name = \"member_id\")  \n    private Member creator;  \n  \n    @OneToMany(mappedBy = \"topic\")  \n    private Set<Permission> permissions = new HasSet<>();  \n  \n    @OneToMany(mappedBy = \"topic\", cascade = CascadeType.PERSIST)  \n    private Set<Pin> pins = new HashSet<>();  \n  \n    @OneToMany(mappedBy = \"topic\", cascade = CascadeType.PERSIST, orphanRemoval = true)  \n    private Set<Bookmark> bookmarks = new HashSet<>();  \n\n\t... 생략\n\n}\n```\n\n이렇게 해서 단 한번의 `Query` 로 존재하는 모든 `Topic` 을 불러 올 수 있었습니다.\n\n하지만, `카테시안 곱` 으로 인해 요청에 대한 응답시간이 어마어마 했습니다. (대략 `20초` 정도?)\n\n### Topic findAll성능 개선 완료\n\n`Topic`을 전체 조회할 때 사실 `Bookmark(즐겨찾기)`, `Pin(핀)` 의 세부 정보가 아닌, 이들의 개수만이 필요하기 때문에, 반정규화를 통해 이 문제를 해결하였습니다.\n\n결론적으로 아래와 같이, `Collection` 중에는 `Permission` 만을 `join` 해오면 되는 거죠!\n\n```java\n@Repository  \npublic interface TopicRepository extends JpaRepository<Topic, Long> {  \n\n    @EntityGraph(attributePaths = {\"creator\", \"permissions\"})  \n    List<Topic> findAll();  \n\n}\n```\n\n근데 이렇게 반정규화를 진행하던 도중, 어쩌다가 `Topic` 을 아래와 같이 바꾸는 일이 있었습니다.\n\n```java\n@Entity  \n@NoArgsConstructor(access = PROTECTED)  \n@Getter  \npublic class Topic extends BaseTimeEntity {  \n\n\t... 생략\n  \n    @ManyToOne(fetch = FetchType.LAZY)  \n    @JoinColumn(name = \"member_id\")  \n    private Member creator;  \n  \n    @OneToMany(mappedBy = \"topic\")  \n    private Set<Permission> permissions = new HasSet<>();  \n  \n    @OneToMany(mappedBy = \"topic\", cascade = CascadeType.PERSIST)  \n    private List<Pin> pins = new ArrayList<>(); // Set --> List 로 바꿈\n  \n    @OneToMany(mappedBy = \"topic\", cascade = CascadeType.PERSIST, orphanRemoval = true)  \n    private Set<Bookmark> bookmarks = new HashSet<>();  \n\n\t... 생략\n\n}\n```\n\n이 때 `Collection` 의 자료구조를 `Set` 만을 썼을때보다 속도가 굉장히 빨라졌었습니다.\n\n이 때 당시에 모두 이에 대해 왜 이런 것이지? 하는 의문을 가졌었지만, 시간이 없어 어쩔 수 없이 넘어갔었습니다.\n\n그리고 시간이 지나, 어느정도 여유가 생긴 지금, 해당 문제에 대해 탐구해보고자 글을 작성하게 된 것입니다.\n\n## 재연\n\n### 상황을 그때와 동일하게 구성해보자.\n\n`프로시저를` 통해 `Local DB` 에다가 `Topic`, `Bookmark` 데이터를 `10만개` 가량을 넣어주고 테스트를 진행했습니다. (내 컴퓨터 살려..)\n\n`Pin` 데이터를 넣지 않은 이유는, 현재 `Pin` 은 `반정규화`가 진행되어 있어 `Topic` 전체 목록을 조회할 때, 성능에 전혀 영향을 끼치지 않기 때문입니다.\n\n그렇다고 `Pin` `반정규화`를 풀자니, 요청과 응답 시간이 비 정상적으로 너무 길어졌습니다. (대략 1분 30초 정도)\n\n그렇기 때문에 일단 `Pin` 은 일단 `반정규화`를 유지하였고, `Bookmark` 만 `반정규화`를 해제하고 진행하였습니다.\n\n그렇기 때문에 테스트를 위해서 `자료구조`를 변경하게 될 `Collection` 은 사실상 `Permission` 과 `Bookmark` 뿐인 것 입니다.\n\n### 테스트 진행\n\n말씀드린 두 `Collection`의  `자료구조`를 바꿔가며 테스트 해본 결과는 아래와 같습니다. (`Permission`, `Bookmark` 모두 `Set` 이 아닌 경우는 `MultipleBagFetchException`  이 발생하기 때문에 테스트하지 않았습니다.)\n\n- Permission, Bookmark 모두 Set\n```txt\n[http-nio-8080-exec-2] 2042 INFO  com.mapbefine.mapbefine.common.filter.LatencyLoggingFilter - Latency : 5.442s, Query count : 1, Request URI : /topics\n```\n\n- Permission  만 Set \n```txt\n[http-nio-8080-exec-3] 2181 INFO  com.mapbefine.mapbefine.common.filter.LatencyLoggingFilter - Latency : 7.074s, Query count : 1, Request URI : /topics\n```\n\n- Bookmark 만 Set\n```txt\n[http-nio-8080-exec-1] 2072 INFO  com.mapbefine.mapbefine.common.filter.LatencyLoggingFilter - Latency : 5.348s, Query count : 1, Request URI : /topics\n```\n\n위 테스트 결과들만으로는 `유의미한 차이`가 보이지 않아 `원인`을 추론해보기 어려웠습니다.\n\n### 지금까지 무의미한 데이터로 테스트 해본 것은 아닐까?\n\n위와 같이 테스트하다가, 문득 `Permission` 에 `데이터`도 넣어봐야 유의미하지 않을까? 란 생각이 머리를 스쳐 지나갔고, `Permission` 데이터도 추가해주었습니다.\n\n하지만, `Permission` 을 추가해주니, `카제인 곱`이 엄청나게 발생되어, `Permission`, `Bookmark` 각각 데이터 개수가 `3000개`만 넘어가도 `Java Heap` 이 터지는 예외가 발생하게 되어, 적당히 `2000` 개 가량의 데이터를 각각 넣어주고, 이어서 테스트를 진행해본 결과 아래와 같은 결과가 나오게 되었습니다.\n\n- Permission 과 Bookmark 모두  Set\n```txt\n[http-nio-8080-exec-3] 1863 INFO  com.mapbefine.mapbefine.common.filter.LatencyLoggingFilter - Latency : 4.924s, Query count : 1, Request URI : /topics\n```\n\n- Permission 만 Set 일 때\n```txt\n[http-nio-8080-exec-2] 1952 INFO  com.mapbefine.mapbefine.common.filter.LatencyLoggingFilter - Latency : 5.159s, Query count : 1, Request URI : /topics\n```\n\n- Bookmark 만 Set 일 때\n```txt\n[http-nio-8080-exec-3] 2000 INFO  com.mapbefine.mapbefine.common.filter.LatencyLoggingFilter - Latency : 7.253s, Query count : 1, Request URI : /topics\n```\n\n테스트 데이터를 변경하더라도, 역시나 `유의미한 차이`를 볼 수 없었습니다.\n\n### 내린 결론 (가설)\n\n`Set` 자료구조를 사용함에 따라, `List` 보다는 부하가 더 발생할 수 있다고 생각합니다.\n\n자료구조 특성상 `Set` 은 중복을 제거해주는 연산을 실행해주어야 하니까요.\n\n하지만, 어짜피 `List` 를 사용하더라도 `hibernate` 에서 `distinct` 를 통해 `중복`을 제거해주기 때문에 더더욱이 유의미한 성능상의 차이를 가져오지 못하는 것 같습니다.\n\n정말 많이 테스트해보면서, 가끔 컴퓨터의 상태에 따라 응답시간이 비정상적으로 길어지는 경우가 있었습니다.\n\n저희는 그것을 보았던 것 아닐까요??\n\n## 이대로 끝내기는 아쉬우니까!\n\n### JPA 에서 Set 을 사용할 때 주의할 점\n\n`문제`를 탐구하다가 `재미있는 글`을 발견했습니다.\n\n[JPA 에서 Set 을 사용할 때 주의점](https://www.inflearn.com/questions/321256/collection-type%EC%9C%BC%EB%A1%9C-set-%EB%8C%80%EC%8B%A0-list%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94-%EC%9D%B4%EC%9C%A0%EA%B0%80-%EC%9E%88%EB%8A%94%EC%A7%80%EC%9A%94)\n\n질문은 아래와 같았습니다.\n\n```txt\nCollection type으로 Set 대신 List를 사용하시는 이유가 궁금합니다.\n\n지금까지 나온 Collection들이 모두 unique한 Entity(또는 값 타입)들의 collection이기 때문에, Set을 활용할 경우 중복 확인 관련 부분이 깔끔해지고, 다른 질문의 답변에서 답해주신대로 값 타입 컬렉션에도 row를 모두 날리고 다시 넣는 문제를 막을 수 있어 Set에 대해 좋은 인상을 가지게 되었습니다.\n\n그런데 기본적으로 예제가 List를 사용하여, Set을 사용하였을 때 제가 놓친 문제가 있는지 의문이 들었습니다.\n```\n\n그에 대한 영한님의 답변은 이랬습니다.\n\n```txt\n안녕하세요. Catnip님\n\n좋은 질문입니다. Set이 개념적으로 좋지만 실무에서는 성능 이슈가 있습니다.\n\nSet은 중복을 제거해야 하는데, 그렇다는 것은 기존 데이터 중에 중복이 있는지 비교를 해야 합니다. 이게 일반적으로는 크게 문제가 없는데, 지연 로딩으로 컬렉션을 조회했을 때 문제가 됩니다.\n\n컬력션이 아직 초기화 되지 않은 상태에서 컬렉션에 값을 넣게 되면 프록시가 강제로 초기화 되는 문제가 발생합니다. 왜냐하면 중복 데이터가 있는지 비교해야 하는데, 그럴러면 컬렉션에 모든 데이터를 로딩해야 하기 때문입니다.\n\n반면에 List는 이런 중복 체크가 필요없이 때문에 데이터를 추가할 때 초기화가 발생하지 않습니다.\n\n감사합니다.\n```\n\n아주 흥미로웠습니다.\n\n이를 제대로 확인해보기 위해서 테스트를 진행하였습니다.\n\n### 테스트\n\n```java\n@Test  \n@Transactional  \nvoid Topic의_Collection_의_자료구조에_따른_초기화를_확인해보자() {  \n    //given  \n    Member savedMember = memberRepository.save(MemberFixture.create(\"member\", \"member@naver.com\", Role.USER));  \n    Topic savedTopic = topicRepository.save(TopicFixture.createPublicAndAllMembersTopic(savedMember));  \n    Location savedLocation = locationRepository.save(LocationFixture.create());  \n  \n    // when  \n    entityManager.clear();  \n    Topic findTopic = topicRepository.findById(savedTopic.getId()).get();  \n    Pin savedPin = pinRepository.save(PinFixture.create(savedLocation, savedTopic, savedMember));  \n  \n    // then  \n    System.out.println(\"=============Add Pin 이전\");  \n    findTopic.addPin(savedPin);  \n    System.out.println(\"=============Add Pin 이후\");  \n    entityManager.flush();  \n}\n```\n\n이와 같이 테스트 코드를 짜고 `Pins` 를 `List` 혹은 `Set` 으로 진행해보았다.\n\n- Pins 가 List 일 때 쿼리\n```txt\n... 이전 쿼리들\n=============Add Pin 이전\n=============Add Pin 이후\nHibernate: \n    update\n        topic \n    set\n\t    ... 수 많은 컬럼들\n    where\n        id=?\n```\n\n- Pins 가 Set 일 때 쿼리\n```txt\n... 이전 쿼리들\n=============Add Pin 이전\nHibernate: \n    select\n\t\t... 수 많은 컬럼들\n    from\n        pin p1_0 \n    left join\n        member c1_0 \n            on c1_0.id=p1_0.member_id \n    left join\n        location l1_0 \n            on l1_0.id=p1_0.location_id \n    where\n        p1_0.topic_id=? \n        and (\n            p1_0.is_deleted = false\n        ) \n=============Add Pin 이후\nHibernate: \n    update\n        topic \n    set\n\t\t... 수 많은 컬럼들\n    where\n        id=?\n```\n\n영한님의 말씀대로 `List` 는 `Collection` 에 값을 `추가` 를 진행할 때, 기존의 데이터가 필요 없으니, 초기화를 진행하지 않지만, `Set` 을 쓰는 경우 중복을 방지하기 위해 기존의 데이터가 필요하기 때문에 `select` 를 통해 값을 가져와 초기화를 진행해주는 것을 볼 수 있었습니다.\n\n즉, 이렇게 `fetch` 전략으로 `Lazy Loading` 을 사용하는 경우 `자료구조`로 `Set` 을 사용하는 경우, `연관관계 매핑`을 하게 되었을 때, 해당 `부작용`이 발생할 수 있는 것입니다.\n\n조심해서 써야겠습니다.\n\n## 최종적인 결론\n\n이 글의 최종적인 결론은 아래와 같습니다.\n\n- 사실 `Set` 과 `List` 로 인한 `성능 차이`는 `유의미하지 않은` 것 같다. 우리가 착각했던 것일지도..?\n- 하지만, `Set` 을 무지성으로 써도 되는 것은 아니다, 이로부터 얻는 부작용이 상당히 많으니, 고심해서 사용하자 (순서 보장 x, 위에서 설명한 초기화 문제)\n\n긴 글 봐주셔서 정말 감사합니다~!\n"},{"excerpt":"이 글은 우테코 괜찮을지도의 가 작성하였습니다. 삭제 기능에 대한 리팩터링 중, 회원 차단에 대한 기존 테스트가 실패해 이를 해결해야 했는데요. JPA에 대한 지식이 부족한 상태에서 삽질을 하며 알게 된 것들을 기록하고자 합니다. 문제 상황 1 : 쿼리의 발생 시점 찾기 도메인: 회원 차단 기능 도메인에 대해 먼저 설명드리겠습니다. 관리자 API에서 회원…","fields":{"slug":"/trouble-shooting-jpa-delete-and-persistence/"},"frontmatter":{"date":"October 13, 2023","title":"JPA 엔티티를 삭제할 때 영속성과 연관 관계가 중요한 이유","tags":["Spring Data JPA","Hibernate","JPQL","트러블슈팅"]},"rawMarkdownBody":"> \n> 이 글은 우테코 괜찮을지도의 `도이`가 작성하였습니다.\n\n삭제 기능에 대한 리팩터링 중, 회원 차단에 대한 기존 테스트가 실패해 이를 해결해야 했는데요.  \nJPA에 대한 지식이 부족한 상태에서 삽질을 하며 알게 된 것들을 기록하고자 합니다.\n\n## 문제 상황 1 : 쿼리의 발생 시점 찾기\n\n### 도메인: 회원 차단 기능\n도메인에 대해 먼저 설명드리겠습니다.  \n관리자 API에서 회원을 차단하면, 차단한 회원의 지도 `Topic`, 핀 `Pin`, 핀 이미지 `PinImage`를 삭제 상태(soft delete)로 변경합니다.  \n그리고 매핑 테이블 역할을 하는 엔티티인 `Bookmark 즐겨찾기`, `Atlas 모아보기`, `Permission 권한`은 실제로 삭제(hard delete)합니다.\n\n\n```java\n    public void blockMember(Long memberId) {\n        Member member = findMemberById(memberId);\n        member.updateStatus(Status.BLOCKED);\n\n        deleteAllRelated(member);\n    }\n\n    private void deleteAllRelated(Member member) {\n        List<Long> pinIds = extractPinIdsByMember(member);\n        Long memberId = member.getId();\n\n        permissionRepository.deleteAllByMemberId(memberId);\n        atlasRepository.deleteAllByMemberId(memberId);\n        bookmarkRepository.deleteAllByMemberId(memberId);\n        pinImageRepository.deleteAllByPinIds(pinIds);\n        pinRepository.deleteAllByMemberId(memberId);\n        topicRepository.deleteAllByMemberId(memberId);\n    }\n```\n\n아래와 같이 동작하기를 기대했습니다.\n\n1. 차단할 회원에 대한 정보 조회\n2. 회원의 상태를 차단으로 변경하는 update 쿼리 발생\n3. 매핑 테이블 엔티티들을 먼저 삭제해야 함, 이 때 delete 쿼리 발생\n4. 주요 도메인 엔티티들을 삭제 상태로 변경하는 update 쿼리 발생\n\n### 예상과 다른 영속 동작\n테스트 코드는 아래와 같습니다.\n\n```java\n    @DisplayName(\"Member를 차단(탈퇴시킬)할 경우, Member가 생성한 지도, 핀, 핀 이미지를 삭제 상태(soft delete)로 변경한다.\")\n    @Test\n    void blockMember_Success() {\n        //given\n        // ...    \n        // 객체 생성, 저장 및 기존 상태 검증 코드 생략\n        // ...\n            \n        //when\n        adminCommandService.blockMember(member.getId());\n\n        //then\n        Member blockedMember = memberRepository.findById(member.getId()).get();\n\n        assertAll(\n            () -> assertThat(blockedMember.getStatus()).isEqualTo(Status.BLOCKED), // 실패\n            () -> assertThat(bookmarkRepository.existsByMemberIdAndTopicId(member.getId(), topic.getId()))\n            .isFalse(), // 실패\n            () -> assertThat(atlasRepository.existsByMemberIdAndTopicId(member.getId(), topic.getId())).isFalse(), // 실패\n            () -> assertThat(permissionRepository.existsByTopicIdAndMemberId(topic.getId(), member.getId()))\n            .isFalse() // 실패\n            () -> assertThat(topicRepository.existsById(topic.getId())).isFalse(), \n            () -> assertThat(pinRepository.existsById(pin.getId())).isFalse(),\n            () -> assertThat(pinImageRepository.existsById(pinImage.getId())).isFalse(),\n        );\n    }\n```\n\n\n하지만 테스트가 실패해 로그를 보니, 실제 동작은 아래와 같았습니다. 😧😧\n\n1. 차단할 회원에 대한 정보 조회\n2. ~~회원의 상태를 차단으로 변경하는 update 쿼리 발생~~\n3. ~~매핑 테이블 엔티티들을 먼저 삭제해야 함, 이 때 delete 쿼리 발생~~\n4. 주요 도메인 엔티티들을 삭제 상태로 변경하는 update 쿼리 발생\n\n`// when` 절의 코드를 호출한 뒤 entityManager로 flush, clear를 해주어도 마찬가지였습니다.  \n\n## 원인\n이전에는 잘 통과하던 테스트인데, 왜 갑자기 예상과 다르게 작동할까요?  \nJPA 영속성 컨텍스트의 쓰기 지연 때문이었습니다.  \n\n1. hard delete 메서드를 통해 해당 id를 가진 엔티티를 영속성 컨텍스트에서 제거한다.\n2. soft delete 메서드를 통해 update를 호출하면서, 연관된 엔티티들이 모두 영속화된다.  \n   ➡️ (1)에서 delete 해도, 2에서 조회할 때 함께 불러와지는 `member`, `permission`, `atlas`, `bookmark`까지 다시 영속화된다.   \n3. 영속성 컨텍스트에는 `(차단 상태가 아닌)member`, `permission`, `atlas`, `bookmark`가 존재한다.\n4. `blockMember()` 호출 후 flush를 할 때, 영속성 컨텍스트의 상태를 기준으로 쿼리가 발생한다.  \n   ➡️ member의 차단 상태에 대한 변경 감지도 되지 않고, delete 쿼리도 나가지 않는다.\n\n그래서 `blockMember()` 메서드를 호출한 뒤 flush를 해줘도 소용이 없었던 것입니다.  \n\n\n## 해결\n\n단순히 해결부터 해보자면,  \nsoft delete 메서드로 인한 영속화가 되기 이전에 flush해서 member의 변경, hard delete에 대한 쿼리를 발생시키면 됩니다.  \n\n\n### flush로 쿼리 발생 시점 조정하기\n\n아래 처럼 서비스 단에서 해주거나, `@Modifying` 어노테이션을 사용할 수 있습니다.\n```java\n    private void deleteAllRelated(Member member) {\n        permissionRepository.deleteAllByMemberId(memberId);\n        atlasRepository.deleteAllByMemberId(memberId);\n        bookmarkRepository.deleteAllByMemberId(memberId);\n        // flush!\n        bookmarkRepository.flush();\n        pinImageRepository.deleteAllByPinIds(pinIds);\n        pinRepository.deleteAllByMemberId(memberId);\n        topicRepository.deleteAllByMemberId(memberId);\n    }\n```\n## 문제 상황 2 : 테스트에서 발생하지 않는 일부 쿼리\n\n그런데도 테스트는 성공하지 않았습니다. 🥲  \n`delete bookmark~` 쿼리는 여전히 발생하지 않고 있었습니다.  \n\n테스트 메서드와 `blockMember()`는 같은 트랜잭션으로 묶이기 때문에 `// when`절에서의 영속화 상태 때문일 것이라 짐작했습니다.  \n`bookmark`를 참조하는 `topic`, 또는 `member` 객체가 영속화되어있기 때문에 delete 쿼리가 나가지 않는 것이라 생각했습니다.  \n\n그래서 이에 대해서는 `blockMember()` 호출 전에 `testEntityManager.clear()`로 영속성 컨텍스트를 초기화해두는 것으로 해결했습니다.  \n\n\n**하지만 정확한 원인이 궁금했습니다. \n왜 `atlas`, `permission`은 삭제되고 `bookmark`만 삭제되지 않았을까요?**  \n\n## 원인\n다른 매핑 테이블 엔티티들과 `bookmark`의 차이점을 살펴보았습니다.  \n해당 엔티티만이 `topic`과의 연관 관계에서 `CasecadeType.PERSIST`가 걸려 있었습니다.\n\n```java\n    // Topic.class\n    @OneToMany(mappedBy = \"topic\", cascade = CascadeType.PERSIST, orphanRemoval = true)\n    private List<Bookmark> bookmarks = new ArrayList<>();\n```\n\n테스트 메서드의 트랜잭션 내에서, 영속성 컨텍스트에 존재하는 `topic`에 `bookmark`가 살아있기 때문에  \n`PERSIST OPERATION`이 발생하고 `bookmark`에 대한 delete 쿼리는 무시됩니다.  \n\n> [JPA 2.2 specification](https://download.oracle.com/otndocs/jcp/persistence-2_2-mrel-eval-spec/index.html) 문서 3.2 장 Entity Instance's Life Cycle에 따르면,  \n> flush가 발생할 때 `CascadeType.PERSIST`나 `CascadeType.ALL`이 있을 경우 자식에 연쇄적으로 `PERSIST OPERATION`이 발생합니다. \n> `PERSIST OPERATION`은 연관 관계 매핑된 list의 엔티티에 대해 모두 이루어지며, 기존에 없던 값이면 새로 저장합니다.\n\n## 해결\n이에 대해서 엔티티에 걸어놓은 조건에 따라 정상적으로 동작하도록 하려면,   \n`bookmarkRepository`를 통해 delete 쿼리를 호출하는 대신 연관 관계를 제거하는 방식으로 삭제해주었어야 했던 것입니다.\n\n```java\n    // Topic.class\n    public void removeBookmarkBy(Member member) {\n        bookmarks.stream()\n        .filter(bookmark -> bookmark.getMember().isSame(member))\n        .findFirst()\n        .ifPresent(this::removeBookmark);\n        bookmarkCount--;\n    }\n\n    // AdminCommandService.class\n    private void deleteAllRelatedMember(Member member) {\n        List<Long> pinIds = extractPinIdsByMember(member);\n        Long memberId = member.getId();\n\n        permissionRepository.deleteAllByMemberId(memberId);\n        atlasRepository.deleteAllByMemberId(memberId);\n        // 변경된 부분\n        topicRepository.findTopicsByBookmarksMemberId(memberId)\n            .forEach(topic -> topic.removeBookmarkBy(member));\n        atlasRepository.flush();\n        pinImageRepository.deleteAllByPinIds(pinIds);\n        pinRepository.deleteAllByMemberId(memberId);\n        topicRepository.deleteAllByMemberId(memberId);\n    }\n```\n\n아래와 같이 `bookmark`에 대한 삭제 로직을 수정하니,  \n테스트 코드에서 별도의 `clear`를 호출하지 않아도 잘 통과하는 것을 확인할 수 있었습니다.\n\n\n## 결론\n이번 삽질을 계기로 JPA를 잘 학습한 뒤 사용해야 한다는 교훈을 다시 한 번 몸소 느꼈습니다..  \n\n엔티티의 생명 주기에 대해 잘 이해하고 객체를 생성 및 삭제해야한다는 것, 삭제할 때에도 연관 관계의 관리가 중요하다는 것을 알았습니다.\n이처럼 예상하지 못한 동작을 피하기 위해 삭제 로직에서도 연관 관계 편의 메서드를 정의하는 방식으로 코드를 잘 작성할 필요가 있어 보입니다. \n\n\n## 참고 자료\n- [[Spring boot] JPA Delete is not Working, 영속성와 연관 관계를 고려했는가.](https://velog.io/@jsb100800/spring-12)  \n- [[jpa] CascadeType.PERSIST를 함부로 사용하면 안되는 이유](https://joont92.github.io/jpa/CascadeType-PERSIST%EB%A5%BC-%ED%95%A8%EB%B6%80%EB%A1%9C-%EC%82%AC%EC%9A%A9%ED%95%98%EB%A9%B4-%EC%95%88%EB%90%98%EB%8A%94-%EC%9D%B4%EC%9C%A0/)\n\n"},{"excerpt":"이 글은 우아한테크코스 괜찮을지도팀의 가 작성했습니다. 배경 CPU 코어가 하나인 컴퓨터라도 수십 또는 수백 개의 쓰레드를  지원할 수 있습니다.\n 하지만, 실제로 하나의 코어는 하나의 쓰레드만 실행할 수 있습니다.\n 을 통해, 하나의 코어에서도 여러 개의 쓰레드를 동시에 지원할 수 있는 것이죠. 물론, 두 개의 쓰레드 A, B가 존재할 때 이를 순차적으…","fields":{"slug":"/how-to-hikariCP/"},"frontmatter":{"date":"October 10, 2023","title":"HikariCP 적용기","tags":["데이터베이스","HikariCP","커넥션 풀"]},"rawMarkdownBody":"\n> 이 글은 우아한테크코스 괜찮을지도팀의 `쥬니`가 작성했습니다.\n### 배경\n\nCPU 코어가 하나인 컴퓨터라도 수십 또는 수백 개의 쓰레드를 `동시에` 지원할 수 있습니다.\n<br> 하지만, 실제로 하나의 코어는 하나의 쓰레드만 실행할 수 있습니다.\n<br> `쓰레드 스케줄링`을 통해, 하나의 코어에서도 여러 개의 쓰레드를 동시에 지원할 수 있는 것이죠.\n\n물론, 두 개의 쓰레드 A, B가 존재할 때 이를 순차적으로 실행하는 것이 성능적으로는 더 빠릅니다.\n<br> `Context Switching Overhead`가 없기 때문이죠 !\n\n그렇다면, 어플리케이션과 관련된 쓰레드의 개수를 설정할 때, 코어의 개수와 동일하게 가져가면 될까요 ?\n<br> **결론부터 이야기하면, 그렇지 않습니다 !**\n<br> 실제 어플리케이션에서는 데이터를 저장하고 있는 `디스크`를 고려해야 하기 때문입니다.\n\n어플리케이션에서 사용하는 데이터베이스에는 디스크가 존재합니다.\n<br> 데이터를 읽기 위해서는, 물리적인 `Disk Arm과 Spindle`이 동작합니다.\n<br> 원하는 데이터를 찾기 위해 위와 같은 동작을 수행하며, 이때 드는 비용은 상당히 큽니다.\n<br> 이 시간을, `I/O 대기 시간`이라고 부르며, 해당 시간 동안 쓰레드들은 `waiting` 상태로 대기하게 됩니다.\n\n그렇기 때문에, I/O 대기 시간으로 인해 waiting 상태인 쓰레드가 생기게 됩니다.\n<br> 즉, 일하지 않고 놀게 되는 코어가 생기게 됩니다.\n\n그렇다면, 데이터베이스 Connection과 관련된 `Thread Pool`의 크기는 어느 정도로 관리하는 게 좋을까요 ?\n\n### Hikari Connection Pool\n\n`HikariCP` 공식 문서에서는 아래와 같은 추천 공식을 제공하고 있습니다.\n\n`Connection Pool Size = (Core count * 2) + Effective spindle count`\n\n위 공식에서, `Effective spindle count`의 값은 사실상 하드디스크의 개수와 같다고 보면 됩니다.\n<br> 디스크 1개당, 1개의 물리적 spindle을 가지고 있기 때문이죠.\n\n`괜찮을지도` 서비스의 운영 서버 EC2 환경은 2개의 코어와 1개의 디스크를 사용하고 있습니다.\n<br> 이를 위 공식에 대입해 보면, `Connection Pool Size = 2 * 2 + 1 = 5`\n\n**즉, `HikariCP`에서 추천하는 커넥션 풀 사이즈는 5가 나오게 됩니다.**\n\n### 성능 테스트\n`HikariCP`에서 추천하는 `괜찮을지도` 서비스의 커넥션 풀 사이즈는 `5`임을 알 수 있었습니다.\n<br> 하지만, 이는 단순히 이론적인 내용일 뿐 맹신할 수는 없습니다.\n<br> 그래서, `JMETER`를 이용한 성능 테스트를 수행하였습니다.\n<br> 테스트에서는 다른 설정을 동일하게 두고, 커넥션 풀 사이즈만 변경하며 진행했습니다.\n\nConnection Pool Size는 아래와 같이 yml 파일을 작성하여 수정할 수 있습니다.\n```yaml\nspring:\n  datasource:\n    hikari:\n      maximum-pool-size: 5\n```\n\n**- Connection Pool Size 10**\n<br> 기본 설정값인 10으로 설정한 뒤, 테스트를 수행하였습니다.\n![connection_pool_size_10.png](.index_image/connection_pool_size_10.png)\n\n**- Connection Pool Size 5**\n<br> HikariCP에서 제공하는 공식을 통해 도출된 값으로 설정한 뒤, 테스트를 수행하였습니다.\n![connection_pool_size_5.png](.index_image/connection_pool_size_5.png)\n\n유의미한 TPS 차이를 통해, 커넥션 풀 사이즈가 5일 때의 성능이 좋다는 것을 확인할 수 있었습니다.\n<br> 물론, 트래픽 양에 따라, 다른 값을 적용하였을 때가 더 최적의 성능을 나타낼 수 있습니다.\n\n`괜찮을지도` 서비스에서는 성능 테스트 목표치량을 기준으로 테스트를 수행하였기 때문에, 위와 같은 결과가 도출되었습니다.\n\n### 마치며\n**위에서도 이야기했지만, 공식을 통해 도출된 값이 항상 최적인 것은 아닙니다.**\n<br>**각 서비스의 특성에 맞게, 커넥션 풀 사이즈를 설정해 보시면서 테스트를 수행하여 최적의 값을 도출해 내시길 바랍니다.**\n\n또한, 커넥션 풀 외에도 HikariCP에서 튜닝해야할 설정을 추천하고 있습니다.\n<br> 이 부분도 [참고](https://github.com/brettwooldridge/HikariCP/wiki/MySQL-Configuration)하면 좋을 것 같습니다.\n\n### 참고\n[HikariCP docs](https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing)\n<br>[HikariCP MySQL Configuration](https://github.com/brettwooldridge/HikariCP/wiki/MySQL-Configuration)\n"},{"excerpt":"이 글은 우테코 괜찮을지도팀의 가 작성했습니다. N+1과 Fetch join 백엔드에서는 조회 API로 여러 연관 관계로 인해 발생하는 N+1 문제를 해결해야 했는데요. 예를 들면 장소(이하 핀) 다건 조회의 경우, 각 핀이 속한 지도(topic), 위치, 생성자, 핀 이미지들을 모두 별도로 조회하는 심각한 문제가 있었습니다. 지도(topic) 조회 시에…","fields":{"slug":"/jpa-multibag-fetch-exception/"},"frontmatter":{"date":"October 04, 2023","title":"Fetch join 사용 시 MultipleBagFetchException의 발생 이유와 해결 방법","tags":["Spring Data JPA","Hibernate","JPQL","트러블슈팅"]},"rawMarkdownBody":"\n> 이 글은 우테코 괜찮을지도팀의 `도이`가 작성했습니다.\n\n## N+1과 Fetch join\n\n백엔드에서는 조회 API로 여러 연관 관계로 인해 발생하는 N+1 문제를 해결해야 했는데요.  \n예를 들면 장소(이하 핀) 다건 조회의 경우, 각 핀이 속한 지도(topic), 위치, 생성자, 핀 이미지들을 모두 별도로 조회하는 심각한 문제가 있었습니다.  \n지도(topic) 조회 시에도 생성자, 권한 정보, 즐겨찾기 목록을 매번 불러왔고요.   \n\n![img.png](.index_image/img.png)\n\n따라서 함께 가져올 연관 관계들에 대해 `Fetch join`을 적용하는 방식으로 문제에 접근했습니다.  \n\n> `Fetch join`은 JPQL에서 성능 최적화를 위해 제공하는 기능입니다.  \n\n### @EntityGraph\n`Fetch join`을 위한 방법으로는, `@EntityGraph`를 선택했습니다.  \nJPQL에 직접 하드코딩으로 쿼리를 작성하는 것보다, 가독성 및 유지보수성에 더 좋다고 판단했기 때문입니다.\n\n`@EntityGraph`는, 객체를 로딩할 때 런타임 성능을 개선하기 위해 JPA 2.1에서 도입된 기능입니다.  \nJPA 2.0 이전까지는 `FetchType`으로만 로딩 전략을 지정할 수 있었지만   \n이를 통해 객체의 연관 관계 중 그래프로 연결할 것들을 템플릿으로 정의하고, 런타임에 선택할 수 있습니다.  \n원하는 필드들만 쉽게 Fetch join 시킬 수 있는 것이죠.\n\n```java\n// PinRepository.class\n// 해당 쿼리로 데이터를 읽을 때, Topic의 필드로 존재하는 \"location\", \"topic\", \"creator\", \"pinImages\"를 Fetch join으로 불러옵니다.\n@EntityGraph(attributePaths = {\"location\", \"topic\", \"creator\", \"pinImages\"})\nList<Pin> findAllByCreatorId();\n```\n\n## 문제 상황\n`@EntityGraph`는 동적으로 생성되므로  \n해당 어노테이션에 작성한 설정이 잘못 되었어도, 컴파일 타임이 아니라 해당 쿼리를 사용하는 런타임 시점에 예외가 발생합니다.  \n\n여러 필드들을 `attributePaths`에 넣어본 뒤, 로컬 환경에서 API를 호출하며 쿼리 개수 및 지연 시간을 확인하던 중  \n아래와 같은 오류가 발생했습니다.\n\n```\norg.hibernate.loader.MultipleBagFetchException: cannot simultaneously fetch multiple bags: \n[com.mapbefine.mapbefine.topic.domain.Topic.bookmarks, com.mapbefine.mapbefine.topic.domain.Topic.permissions]\n```\n\n호출된 쿼리는 아래와 같았습니다.\n```java\n// TopicRepository.class\n@EntityGraph(attributePaths = {\"creator\", \"permissions\", \"bookmarks\"})\nList<Topic> findAll();\n```\n\n## MultipleBagFetchException의 발생 이유\n간단하게 이야기하면 **`OneToMany` 관계를 1개보다 더 많이 Fetch join** 하려고 했기 때문에 발생한 문제입니다.  \n\"permissons\"와 \"bookmarks\"를 동시에 Fetch join할 수 없습니다.\n\n### Fetch join과 카테시안 곱\nFetch join은 `*ToOne` 관계에는 개수 제한이 없지만, `*ToMany` 관계를 1개만 사용할 수 있습니다.  \nfech join을 여러 개의 컬렉션에 적용한다면, 카테시안 곱에 의해 중복 데이터가 발생하기 때문입니다.  \nHibernate은 이에 대해 `MultipleBagFetchException` 예외를 던져 해당 상황 자체를 막습니다.  \n\n물론 하나의 `OneToMany`를 Fetch join 해도 join 대상인 엔티티 기준으로는 중복이 발생합니다.  \n하지만 이에 대해서는 JPQL에서 지원하는 distinct를 사용해 엔티티의 중복을 제거할 수 있습니다.  \n\n> `Bag`은 Hibernate 용어로, Set과 같이 순서가 없고 List와 같이 중복을 허용하는 자료구조입니다.  \n> 그러나 Java Collection API에는 위와 같은 개념의 자료구조가 없기 때문에, List를 Bag으로 사용합니다.  \n> List 로 초기화한 경우, PersistentBag 이라는 인스턴스로 매핑됩니다.   \n> 반면 Set 으로 초기화한 경우, PersistentSet 이라는 인스턴스로 매핑됩니다.\n\n\n## 해결 방법\n앞서 발생한 상황의 경우,  \n즐겨찾기 개수에 대한 역정규화로 인해 \"bookmarks\"의 Fetch join이 필요가 없어지면서 문제 자체가 사라졌습니다.  \n하지만 해당 예외에 대한 해결 방법과, 이러한 문제를 회피하면서 성능을 개선할 수 있는 방법을 알아두면 도움이 될 것입니다.   \n\n먼저 해당 예외에 대한 단순 해결 방법으로는 아래와 같은 것이 있습니다.   \n### 1. 자료형을 Set으로 변경\nSet은 중복을 허용하지 않기 때문에 이 경우 여러 개의 `*ToMany`를 허용해줍니다.  \n하지만 순서를 보장할 수 없다는 단점이 있습니다.  \n\n> 이로 인해 화면 상 보이는 지도 목록 순서가 매번 바뀌는 문제를 겪기도 했습니다.  \n> Hibernate에서는 DB에서 읽어온 데이터를 저장할 때,  \n> List와 달리 Set에 대해서는 순서 보장을 지원하지 않기 때문에 LinkedHashSet으로도 소용이 없었습니다.\n\n### 2. 자식 엔티티 중 하나에만 Fetch join을 걸고, 나머지는 Lazy loading\n해당 예외를 피하는 방법이긴 하지만, 기존에 목표로 삼던 성능 개선과는 거리가 멀어질 수 있습니다.   \n\n그 외에도 Fetch join 쿼리를 나누어 실행하거나, 쿼리를 여러 개로 나누었다 조립하는 방법도 있습니다.  \n**하지만 결국 원하는 건 쿼리의 수를 줄이고 성능을 개선하는 것인데, 간단하고 좋은 방법 없을까요? 🤔**\n\n### 3. default_batch_fetch_size 설정\n불가피하게 여러 개의 `*ToMany`를 Fetch join 해야 할 경우,  \n2번 방법을 적용하되 이 방법을 사용하면 Lazy loading으로 인해 발생하는 쿼리도 획기적으로 줄일 수 있습니다.\n\nHibernate의 `default_batch_fetch_size` 설정을 바꾸면 여러 개의 `*ToMany`를 사용하고도 N+1 문제를 회피할 수 있기 때문입니다.    \n자식 엔티티를 조회할 때는, 외래키를 사용해 아래와 같은 쿼리가 나갑니다.\n\n```sql\nselect * from permission where topic_id = 1;\nselect * from permission where topic_id = 2;\n// ... 조회할 모든 토픽에 대해 쿼리 발생\nselect * from bookmark where topic_id = 1;\nselect * from bookmark where topic_id = 2;\n// ... 조회할 토픽에 대해 쿼리 발생\n```\n\n하지만 해당 옵션은 지정된 수(size) 만큼, in 절에 부모 key를 사용하는 방식으로 자식 엔티티들을 조회하도록 바꿔줍니다.  \n조회하는 topic 개수 만큼 나가던 쿼리를 각 1번씩으로 줄일 수 있습니다.\n```sql\nselect * from permission where topic_id in (1, 2, 3, ...);\nselect * from bookmark where topic_id in (1, 2, 3, ...);\n```\n\n\n## 참고 자료\n- https://www.baeldung.com/jpa-entity-graph\n- https://www.baeldung.com/java-hibernate-multiplebagfetchexception\n- https://docs.spring.io/spring-data/data-jpa/docs/current/api/org/springframework/data/jpa/repository/EntityGraph.html\n- https://jojoldu.tistory.com/457?fbclid=IwAR132BRMYHrL4D5Pu25YUglIcEN1FGTE2tacFcsVOPAT0MAzwoMX6Flzbe0\n- https://devlog-wjdrbs96.tistory.com/421\n"},{"excerpt":"이 글은 우테코 괜찮을지도의 가 작성하였습니다. 배경 쿼리 개선... 필요할지도? 9월 말, 추석을 앞두고 사용자 유치 계획 실행을 앞두고 있었다. 우리는 행복회로를 돌리며, 많은 사용자들이 서비스에 들어올 것이라고 생각했고, 사용자들에게 좋은 경험을 선사하고 싶었다. 하지만, 문제가 있었다. 많은 사용자가 들어옴에 따라 평소보다 많은 트래픽이 발생할 것…","fields":{"slug":"/trouble-shooting-fetch-type/"},"frontmatter":{"date":"October 04, 2023","title":"FetchType.EAGER, FetchType.LAZY 에 대해서 알아보자!","tags":["Spring Data JPA","JPQL"]},"rawMarkdownBody":"\n> 이 글은 우테코 괜찮을지도의 `매튜`가 작성하였습니다.\n\n## 배경\n\n### 쿼리 개선... 필요할지도?\n\n9월 말, 추석을 앞두고 사용자 유치 계획 실행을 앞두고 있었다.\n\n우리는 행복회로를 돌리며, 많은 사용자들이 서비스에 들어올 것이라고 생각했고, 사용자들에게 좋은 경험을 선사하고 싶었다.\n\n하지만, 문제가 있었다.\n\n많은 사용자가 들어옴에 따라 평소보다 많은 트래픽이 발생할 것이고, 조금 더 좋은 경험을 제공하기 위해 추가한 지도와 핀으로 인해 데이터는 방대해졌다. \n\n자칫하면 사용자에게 좋지 않은 경험을 선사할 수 있다는 생각에 성능 개선을 목표로 삼았다.\n\n때문에 우리는 현재 발생하고 있는 `N + 1` 문제를 해결하고, `인덱스`를 활용하여 빠른 성능 개선을 계획했다.\n\n그 중에서 `N + 1` 문제를 해결하는 과정 중에 해당 글을 작성하게 된 문제가 발생하였다.\n\n### 문제 상황\n\n유저가 `지도` 목록을 조회하려는 경우 비정상적으로 쿼리가 많이나갔다.\n\n쉽게 예상할 수 있듯 당연히 `N + 1` 문제였다.\n\n우리는 해당 `N + 1` 문제를 해결하기 위해서 `fetch join` 을 사용했다.\n\n### N + 1 을 해결해보자!\n\n- Topic Entity 구조 (`지도 == Topic`)\n```java\n@Entity  \n@NoArgsConstructor(access = PROTECTED)  \n@Getter  \npublic class Topic extends BaseTimeEntity {  \n  \n    @Id  \n    @GeneratedValue(strategy = GenerationType.IDENTITY)  \n    private Long id;  \n\n\t... 생략\n  \n    @ManyToOne  \n    @JoinColumn(name = \"member_id\")  \n    private Member creator;  \n  \n    @OneToMany(mappedBy = \"topic\")  \n    private List<Permission> permissions = new ArrayList<>();  \n  \n    @OneToMany(mappedBy = \"topic\", cascade = CascadeType.PERSIST)  \n    private List<Pin> pins = new ArrayList<>();  \n  \n    @OneToMany(mappedBy = \"topic\", cascade = CascadeType.PERSIST, orphanRemoval = true)  \n    private List<Bookmark> bookmarks = new ArrayList<>();  \n  \n    @Column(nullable = false)  \n    @ColumnDefault(value = \"0\")  \n    private int pinCount = 0;  \n  \n    @Column(nullable = false)  \n    @ColumnDefault(value = \"0\")  \n    private int bookmarkCount = 0;  \n\n\t... 생략\n\n}\n```\n\n- Topic Repository \n```java\n@Repository  \npublic interface TopicRepository extends JpaRepository<Topic, Long> {  \n  \n    @EntityGraph(attributePaths = {\"permissions\"})  \n    List<Topic> findAll();\n\n\t... 생략\n}\n```\n\n앞선 `Entity`, `Repository` 는 `지도` 목록을 조회할 때 사용된 `Entity` 및 `Repository` 이다.\n\n마지막으로 `Topic` 에 필요한 정보는 아래와 같다.\n\n- Topic Response\n```json\n{  \n  \"id\" : 1,  \n  \"name\" : \"토픽 이름\",  \n  \"image\" : \"토픽 이미지 링크\",  \n  \"creator\" : \"토픽을 만든자\",  \n  \"pinCount\" : 3,  \n  \"bookmarkCount\" : 5,  \n  \"updatedAt\" : \"2023-10-02T18:00:55.95188832\"  \n}\n```\n\n여기서 사용자에게 `Topic` 목록을 제공하기 위해 부수적으로 필요한 `Entity` 는 `Member` , `Permission` 이었다.\n\n위에서 볼 수 있듯, `Member` 는 `@ManyToOne 기본 fetch 설정`으로 인해 `FetchType.EAGER` 로 설정되고, `Permission` 은 `@OneToMany 기본 fetch 설정` 인 `FetchType.LAZY` 이지만, `@EntityGraph` 를 통해서 `fetch join` 을 해주었기 때문에 당연히 쿼리는 한번만 나갈 줄 알았다.\n\n하지만, 결과는....\n\n```text\n// 데이터 10만개를 기준으로 진행되었음\n[http-nio-8080-exec-2] 16496 INFO  com.mapbefine.mapbefine.common.filter.LatencyLoggingFilter - Latency : 4.649s, Query count : 8, Request URI : /topics\n```\n\n위와 같았고, 우리는 멘붕이 올 수 밖에 없었다.\n\n우리 예상대로라면 분명히 `Query Count` 가 `1`이어야 하는데??\n\n도대체 왜 ?? ㅠㅠㅠ\n\n### 해결했는데 이유를 모르겠어\n\n다른 문제들도 많은데, 해당 문제까지 발생하여 몇 시간 동안 골머리를 앓았다.\n\n그러다 조금의 시간이 흘렀고, 마음을 가다듬고 천천히 쿼리를 뜯어보기 시작했고, 원인을 찾을 수 있었다.\n\n```sql\nHibernate: \n    select\n\t\t... 수많은 컬럼들 ...\n    from\n        topic t1_0 \n    left join\n        permission p1_0 \n            on t1_0.id=p1_0.topic_id\nHibernate: \n    select\n\t\t... 수많은 컬럼들 ...\n    from\n        member m1_0 \n    where\n        m1_0.id=?\n\n\t... 7 번을 member 를 찾아옴\n```\n\n우리는 `@ManyToOne` 의 `기본 fetch 설정`인 `FetchType.EAGER` 로 인해 `Member` 를 `join` 을 통해 가져올 것이라고 생각했지만, 실상은 `Topic` 을 가져올 때 `permission` 은 `join`을 잘해서 가져오지만, `member` 는 `select 쿼리`를 통해 따로 가져오고 있었다.\n\n이로 인해서 `Query Count` 가 `1`이 아니었던 것이었다.\n\n```java\n@EntityGraph(attributePaths = {\"creator\", \"permissions\"})  \nList<Topic> findAll();\n```\n\n해당 문제를 해결하기 위해, 위와 같이 `attributePaths` 에 `creator` 를 추가해주었더니\n\n```text\n[http-nio-8080-exec-5] 16826 INFO  com.mapbefine.mapbefine.common.filter.LatencyLoggingFilter - Latency : 5.941s, Query count : 1, Request URI : /topics\n```\n\n드디어 `Query Count` 를 `1`로 만들 수 있었다.\n\n도대체 왜 그런걸까???\n\n차근차근 알아가보자!\n\n## ManyToOne 테스트\n\n### 테스트를 통해서 생각을 굳혀보자!\n\n일단 이전 상황들로 미루어 보았을 때, `Eager` 와 `Lazy` 는 단순 `select 시기`를 `결정`하는 것 같다.\n\n그렇기 때문에, `Eager` 로 설정하든 `Lazy` 로 설정하든, 따로 `select` 쿼리를 통해서 가져오는 것이다.\n\n이를 증명하기 위해 몇 가지 테스트를 진행해보자.\n\n`@ManyToOne` 을 진행하기 위해 `대상 Entity` 를 정하고 `Test` 하기 위한 `테스트 코드`를 짜보자!\n\n- Permission (@ManyToOne 컬럼밖에 없어서 딱 테스트하기 좋은 Entity Class 라고 판단)\n\n```java\n@Entity  \n@NoArgsConstructor(access = PROTECTED)  \n@Getter  \npublic class Permission extends BaseTimeEntity {  \n  \n    @Id  \n    @GeneratedValue(strategy = GenerationType.IDENTITY)  \n    private Long id;  \n  \n    @ManyToOne // 여기서 Eager or Lazy 로 진행할 것 \n    @JoinColumn(name = \"topic_id\", nullable = false)  \n    private Topic topic;  \n  \n    @ManyToOne  \n    @JoinColumn(name = \"member_id\", nullable = false)  \n    private Member member;\n\n}\n```\n\n- ManyToOne 을 테스트 하기 위한 테스트 코드\n\n```java\n@ServiceTest  \nclass TestClass {\n  \n    @Autowired  \n    private TopicRepository topicRepository;  \n  \n    @Autowired  \n    private MemberRepository memberRepository;  \n  \n    @Autowired  \n    private PermissionRepository permissionRepository;  \n  \n    @Autowired  \n    private TestEntityManager testEntityManager;  \n  \n    private Member member;  \n    private Topic topic;  \n    private Permission permission;  \n  \n    @BeforeEach  \n    void beforeEach() {  \n        // 멤버를 저장한다.  \n        member = memberRepository.save(MemberFixture.create(\"member\", \"member@naver.com\", Role.USER));  \n        // 토픽을 저장한다.  \n        topic = topicRepository.save(TopicFixture.createPublicAndAllMembersTopic(member));  \n        // 권한을 저장한다.  \n        permission = permissionRepository.save(Permission.createPermissionAssociatedWithTopicAndMember(topic, member));  \n  \n        // 영속성 컨텍스트 초기화 (초기화 안하면 findById 때 쿼리가 안 날라감)\n        testEntityManager.clear();  \n    }  \n  \n    @Test  \n    void permissionManyToOneFindById() {  \n        Permission permissionByFindById = permissionRepository.findById(permission.getId()).get();  \n          \n        assertThat(permissionByFindById.getTopic()).isEqualTo(topic);  \n        assertThat(permissionByFindById.getMember()).isEqualTo(member);  \n    }\n}\n```\n\n위와 같이 테스트 코드를 짜고, `@ManyToOne fetchType` 은 `Eager` (기본 설정) 로 설정하고 테스트를 진행했다.\n\n당연히 추가적인 `select` 쿼리가 날아가겠지? ㅎㅎ\n\n### 예상과 다른 결과\n\n```sql\nHibernate: \n    select\n\t\t... 수많은 컬럼들\n    from\n        permission p1_0 \n    join\n        member m1_0 \n            on m1_0.id=p1_0.member_id \n    join\n        topic t1_0 \n            on t1_0.id=p1_0.topic_id \n    left join\n        member c1_0 \n            on c1_0.id=t1_0.member_id \n    where\n        p1_0.id=?\n```\n\n아니 도대체 왜 ???\n\n예상대로라면 `select` 쿼리가 나가야 하는데...\n\n이해가 되지 않는다.\n\n왜 `select` 했다가 지 마음대로 `join` 해서 오는지 갈대같은 `JPA` 의 마음을 알 수가 없다.\n\n이 결과를 보고 이전과 다른게 뭐지... 하면서 곰곰히 생각해보았다.\n\n이 때 내가 발견한 차이점은 단 하나였다.\n\n# 이전에는 목록 조회(findAll()), 이번에는 단건 조회(findById())이다.\n\n### 호다닥 findAll 로 테스트\n\n```java\n@Test  \nvoid permissionManyToOneFindAll() {  \n    List<Permission> permission = permissionRepository.findAll();  \n}\n```\n\n위와 같이 테스트를 실행해보았다.\n\n결과는??\n\n```sql\nHibernate: \n    insert \n    into\n        permission\n        (created_at,member_id,topic_id,updated_at,id) \n    values\n        (?,?,?,?,default)\nHibernate: \n    select\n\t    ... 수많은 컬럼들 ...\n    from\n        permission p1_0\nHibernate: \n    select\n\t    ... 수많은 컬럼들 ...\n    from\n        member m1_0 \n    where\n        m1_0.id=?\nHibernate: \n    select\n\t    ... 수많은 컬럼들 ...\n    from\n        topic t1_0 \n    left join\n        member c1_0 \n            on c1_0.id=t1_0.member_id \n    where\n        t1_0.id=?\n```\n\n역시나 예상대로 `findAll` 인 경우는 똑같이 `Eager` 이더라도 `join` 을 해서 가져오지 않는다.\n\n`Eager` 로 `findById`, `findAll` 을 테스트 해봤으니\n\n`Lazy` 로 더 테스트를 진행해서 가설을 사실로 굳혀보자!\n\n### Lazy 테스트\n\n먼저 `findById`로 테스트를 진행해보자.\n\n```java\n@Test  \nvoid permissionManyToOneFindById() {  \n    Permission permissionByFindById = permissionRepository.findById(permission.getId()).get();  \n  \n    assertThat(permissionByFindById.getTopic()).isEqualTo(topic);  \n    assertThat(permissionByFindById.getMember()).isEqualTo(member);  \n}\n```\n\n```sql\nHibernate: \n    select\n\t\t... 수많은 컬럼들 ...\n    from\n        permission p1_0 \n    where\n        p1_0.id=?\nHibernate: \n    select\n\t\t... 수많은 컬럼들 ...\n    from\n        topic t1_0 \n    left join\n        member c1_0 \n            on c1_0.id=t1_0.member_id \n    where\n        t1_0.id=?\n```\n\n결과는 당연하다.\n\n`Lazy` 하게 가져오니 `findById` 로 가져오더라도 `join` 을 하지 않은 것이고, `getTopic()` 을 할 때 `Topic` 을 가져왔기 때문에 `select` 쿼리가 나갔다.\n\n근데 `member` 를 조회하는 `select` 쿼리가 없다. \n\n왜 그럴까?\n\n이유는, 이번에 처음 알았는데 `assertJ` 로 테스트를 진행할 때 단 하나라도 예상한 결과가 나오지 않아 테스트가 실패하게 되면 그 즉시 테스트가 종료되는 것 같다.\n\n그래서 뒤에 있는 `getMember()` 구문은 실행되지 않은 것이다.\n\n어쨌든, 본론으로 돌아와 `findAll` 도 테스트를 진행해보자.\n\n```java\n@Test  \nvoid permissionManyToOneFindAll() {  \n    List<Permission> permission = permissionRepository.findAll();  \n  \n    assertThat(permission.get(0).getTopic()).isEqualTo(topic);  \n    assertThat(permission.get(0).getMember()).isEqualTo(member);  \n}\n```\n\n위와 같이 테스트를 진행했고, 나간 쿼리는 당연히 위와 동일할 것이다.\n\n```sql\nHibernate: \n    select\n\t\t... 수많은 컬럼들 ...\n    from\n        permission p1_0\nHibernate: \n    select\n\t\t... 수많은 컬럼들 ...\n    from\n        topic t1_0 \n    left join\n        member c1_0 \n            on c1_0.id=t1_0.member_id \n    where\n        t1_0.id=?\n```\n\n역시 동일하다.\n\n### ManyToOne 테스트를 통해 확실하게 유추할 수 있는 것\n\n`findAll` 과 같은 목록 조회는 `Eager`, `Lazy` 가 정말 `select 시기`만을 결정하지만, `findById` 과 같은 단건 조회는 `Eager` 로 설정하게 되면, `fetchType` 이 `select 시기 결정`을 넘어 `join` 여부까지 결정할 수 있는 것이다. (최적화)\n\n결과야 뻔하긴 하지만, 남은 `OneToMany` 테스트들도 진행해서 위 사실을 더욱 더 굳혀보자.\n\n## OneToMany\n\n### 테스트 준비\n\n`ManyToOne` 테스트와 마찬가지로 `OneToMany` 테스트를 진행할 `대상 Entity` 와 `Test 코드`를 짜보자!\n\n- Member Entity (OneTOMany 컬럼만 있어서 딱 적합)\n```java\n@Entity  \n@NoArgsConstructor(access = PROTECTED)  \n@Getter  \npublic class Member extends BaseTimeEntity {  \n  \n    @Id  \n    @GeneratedValue(strategy = GenerationType.IDENTITY)  \n    private Long id;  \n\n\t... 생략 ...\n  \n    @OneToMany(mappedBy = \"creator\")  \n    private List<Topic> createdTopics = new ArrayList<>();  \n\n\t... 생략 ...\n\n}\n```\n\n- Test 코드\n```java\n@Test  \nvoid memberOneToManyFindById() {  \n    Member memberByFindById = memberRepository.findById(member.getId()).get();  \n    assertThat(memberByFindById.getCreatedTopics().get(0)).isEqualTo(topic);  \n}  \n  \n@Test  \nvoid memberOneToManyFindAll() {  \n    List<Member> members = memberRepository.findAll();  \n    assertThat(members.get(0).getCreatedTopics().get(0)).isEqualTo(topic);  \n}\n```\n\n### Eager 에 대해서 먼저 테스트 해보자!\n\n- findById 로 테스트\n```sql\nHibernate: \n    select\n\t\t... 수많은 컬럼들 ...\n    from\n        member m1_0 \n    left join\n        topic c1_0 \n            on m1_0.id=c1_0.member_id \n    where\n        m1_0.id=?\n```\n\n이쯤되면 당연히 예상할 수 있듯이 `join` 을 해서 가져온다.\n\n- findAll 로 테스트\n```sql\nHibernate: \n    select\n\t\t... 수많은 컬럼들 ...\n    from\n        member m1_0\nHibernate: \n    select\n\t\t... 수많은 컬럼들 ...\n    from\n        topic c1_0 \n    where\n        c1_0.member_id=?\n```\n\n이것도 당연히 예상할 수 있듯, `join` 이 아닌 `select` 을 해서 가져오고, 실제로 `Topic` 에 `createdTopics` 에 접근하지 않더라도 `select` 구문이 발생하게 된다.\n\n왜 ? 지금까지 계속보았듯 `findAll` 과 같은 `목록 조회`에서는 `Eager`, `Lazy` 가 `select 시기`만을 결정하니까\n\n### Lazy 도 테스트 해보자.\n\n정말 뻔하니 그냥 별다른 코멘트 없이 테스트 결과만을 나열하겠다.\n\n- findById\n```sql\nHibernate: \n    select\n\t\t... 수많은 컬럼들 ...\n    from\n        member m1_0 \n    where\n        m1_0.id=?\nHibernate: \n    select\n\t\t... 수많은 컬럼들 ...\n    from\n        topic c1_0 \n    where\n        c1_0.member_id=?\n```\n\n당연히 `join` 하지 않고\n\n- findAll\n```sql\nHibernate: \n    select\n\t\t... 수많은 컬럼들 ...\n    from\n        member m1_0 \n    where\n        m1_0.id=?\n```\n\n당연히 조회하지 않는다면 더 이상 `select` 쿼리를 발생시키지 않는다.\n\n## 최종적인 결론\n\n- `findById` 는 `FetchType` 이 `Eager` 라면 `join` 을 해서 가져와준다 (최적화를 알아서 해주는 것)\n- `findAll` 은 `findById` 와 다르게 `fetch type` 이 `Eager` 인지 `Lazy` 인지에 따라 해당 데이터를 가져오기 위한 `select 쿼리 발생 시기`만을 결정한다. (즉, `fetch type` 으로 인해 `join 여부`가 결정되지 않음)\n\n"},{"excerpt":"이 글은 우테코 괜찮을지도의 가 작성하였습니다. 배경 괜찮을지도 서비스에서는 테스트를  방식으로 수행하고 있습니다.\n란 우리가 알고 있는  테스트에서 따온 네이밍입니다. (서비스 -> 레포지토리까지의 테스트만으로도 E2E라고 불리는지는 잘 모르겠습니다)\n 이때, Layer는 각 계층(Service, Repo 등)을 말합니다. 서비스 계층에서 데이터를 삭제…","fields":{"slug":"/trouble-shooting-modifying-annotation/"},"frontmatter":{"date":"October 02, 2023","title":"@Modifying 어노테이션의 옵션이 정상 동작하지 않는 문제","tags":["Spring Data JPA","Test","@Modifying"]},"rawMarkdownBody":"\n> 이 글은 우테코 괜찮을지도의 `쥬니`가 작성하였습니다.\n\n### 배경\n\n괜찮을지도 서비스에서는 테스트를 `Layer To End` 방식으로 수행하고 있습니다.<br>\n`Layer To End`란 우리가 알고 있는 `E2E` 테스트에서 따온 네이밍입니다. (서비스 -> 레포지토리까지의 테스트만으로도 E2E라고 불리는지는 잘 모르겠습니다)\n<br> 이때, Layer는 각 계층(Service, Repo 등)을 말합니다.\n\n서비스 계층에서 데이터를 삭제하는 테스트를 수행하는 도중, 데이터가 삭제되지 않고 조회되는 문제가 발생하였습니다.\n<br> 지금부터, 그 이야기를 시작해 보려 합니다.\n\n### 문제 상황\n\n문제를 직면한 상황은 `사용자의 즐겨찾기 목록을 모두 삭제하는 상황`이었습니다.\n<br> 테스트를 위해, 각 Repositry를 사용하여 아래와 같이 데이터를 넣어주는 작업을 수행했습니다.\n```java\n    @Test\n    @DisplayName(\"즐겨찾기 목록에 있는 모든 토픽을 삭제할 수 있다\")\n    void deleteAllBookmarks_Success(){\n            // 회원 저장\n            Member member = memberRepository.save(MemberFixture.create(\n            \"member\",\n            \"member@naver.com\",\n            Role.USER\n            ));\n            \n            Topic topic1 = TopicFixture.createPrivateAndGroupOnlyTopic(member);\n            Topic topic2 = TopicFixture.createPrivateAndGroupOnlyTopic(member);\n\n            // 지도 저장\n            topicRepository.save(topic1);\n            topicRepository.save(topic2);\n            \n            Bookmark bookmark1 = Bookmark.createWithAssociatedTopicAndMember(topic1, member);\n            Bookmark bookmark2 = Bookmark.createWithAssociatedTopicAndMember(topic2, member);\n\n            // 즐겨찾기 등록\n            bookmarkRepository.save(bookmark1);\n            bookmarkRepository.save(bookmark2);\n}\n```\n위 코드의 결과로, 사용자(Member)와 지도(Topic)가 생성되어 있을 것이고, 사용자는 자신이 만든 지도를 즐겨찾기(Bookmark)로 등록해 놓은 상황일 것입니다.\n<br> 이후, 아래와 같은 코드를 수행하면 해당 사용자의 즐겨찾기 목록이 전부 삭제되어, 테스트를 통과할 것이라 예상하였습니다.\n```java\n        // 생략 ...\n        \n        // 통과 !\n        assertThat(creatorBefore.getBookmarks()).hasSize(2);\n\n        // 해당 회원의 즐겨찾기 목록 전체 삭제\n        AuthMember user = MemberFixture.createUser(creatorBefore);\n        bookmarkCommandService.deleteAllBookmarks(user);\n        \n        // 실패 !\n        assertThat(bookmarkRepository.findById(creatorBefore.getId())).isEmpty();\n```\n테스트 실패 메시지는 아래와 같았습니다.\n```java\njava.lang.AssertionError: \nExpecting empty but was: [com.mapbefine.mapbefine.bookmark.domain.Bookmark@23504729,\n    com.mapbefine.mapbefine.bookmark.domain.Bookmark@2447e2e]\n```\n즉, 즐겨찾기가 존재하지 않을 것이라고 예상하였지만, 데이터가 존재한다는 의미였습니다.\n<br> 테스트에 사용된 메서드들의 로직적인 오류를 재차 확인하였지만, 발견할 수 없었습니다.\n<br> 그렇다면, 도대체 왜 데이터가 삭제되지 않고 조회되는 것일까요 ?\n\n\n### 원인 파악\n\n위 문제의 원인을 찾기 위해 여러 방법을 시도하던 중, `TestEntityManager`를 통해 즐겨찾기 삭제 메서드 호출 전, 후에 다음과 같은 로직을 추가하였습니다.\n```java\n    @Test\n    @DisplayName(\"즐겨찾기 목록에 있는 모든 토픽을 삭제할 수 있다\")\n    void deleteAllBookmarks_Success() throws InterruptedException {\n        // 생략\n        testEntityManager.flush();\n        testEntityManager.clear();\n\n        bookmarkCommandService.deleteAllBookmarks(user);\n\n        testEntityManager.flush();\n        testEntityManager.clear();\n        // 생략\n    }\n```\n즉, 삭제 메서드를 호출한 뒤, 명시적으로 영속성 컨텍스트를 flush & clear 해준 것입니다.\n<br> 위와 같은 로직을 추가하자, 테스트가 성공적으로 통과했습니다.\n<br> 이로써, 문제 원인은 영속성 컨텍스트와 관련이 있음을 알게 되었습니다.\n\n하지만, 한 가지 의문점이 생겼습니다.\n<br> 분명, 우리는 데이터의 변경이 일어나는 `Repository`의 메서드에는 `@Modifying` 어노테이션과 함께, `clearAutomatically = true`로 설정해 둔 상태였습니다.\n<br> 테스트에서 직면한 문제처럼, 데이터를 수정(삭제)하였더라도 1차 캐시 내부에서는 수정 전 데이터가 존재할 수 있음을 인지하고 있었습니다.\n<br> 이로인해, 수정 관련 쿼리가 실행된 후, 명시적으로 영속성 컨텍스트를 비워주었습니다.\n```java\npublic interface BookmarkRepository extends JpaRepository<Bookmark, Long> {\n\n    @Modifying(clearAutomatically = true)\n    void deleteAllByMemberId(Long memberId);\n\n}\n```\n\n위와 같은 설정을 해두었음에도 불구하고, 영속성 컨텍스트가 비워지지 않았다는 사실을 납득하기 어려웠습니다.\n하지만, 그 원인은 생각보다 쉽게 찾을 수 있었습니다.\n우리가 사용한 `@Modifying` 어노테이션을 확인해 보니, 다음과같이 쓰여있었습니다.\n> Indicates a query method should be considered as modifying query as that changes the way it needs to be executed. <br>\n> **This annotation is only considered if used on query methods defined through a {@link Query} annotation.**<br> It's not \n> applied on custom implementation methods or queries derived from the method name as they already have control over \n> the underlying data access APIs or specify if they are modifying by their name.\n\n우리가 주목할 점은, 위 설명의 두 번째 줄이었습니다.\n<br> 간단하게 설명하자면, `@Modifying` 어노테이션은 `@Query` 어노테이션과 함께 사용될 때만 효력이 있다는 것입니다.\n<br> 즉, 아래와 같은 `NamedQeury`를 사용할 때는 옵션값을 넣어주더라도 동작하지 않았던 것이죠.\n```java\npublic interface BookmarkRepository extends JpaRepository<Bookmark, Long> {\n    @Modifying(clearAutomatically = true)\n    void deleteAllByMemberId(Long memberId);\n}\n```\n\n### 문제 해결\n\n(1) `@Query` 어노테이션을 사용하여 직접 쿼리를 작성하는 방법과, (2) 테스트 코드에서 flush & clear를 명시적으로 수행하는 방법이 있었습니다.\n<br> 단순히 테스트 통과에 목적을 둔 것이 아니기 때문에, 실제 프로덕트 코드에서도 예상치 못한 동작을 방지하기 위해 (1)번 방법을 선택하였습니다.\n<br> 이에 따라, `Named Query -> JPQL`로 변경함으로써 문제를 해결할 수 있었습니다.\n```java\npublic interface BookmarkRepository extends JpaRepository<Bookmark, Long> {\n    @Modifying(clearAutomatically = true)\n    @Query(\"delete from Bookmark b where b.member.id = :memberId\")\n    void deleteAllByMemberId(@Param(value = \"memberId\") Long memberId);\n}\n\n```\n"},{"excerpt":"이 글은 우아한테크코스 괜찮을지도팀의 가 작성했습니다. 지난 글 GitHub Actions로 CI/CD 구축하기에서 현재 저희 프로젝트의 인프라 구조를 간략하게 이미지로 설명드렸습니다. 다시 이미지를 보여드리자면, 서버의 앞단에서 Nginx를 사용하고 있는데요.  ⚠️ 편의상 개발 서버, DB 서버 부분은 생략하고 확대한 이미지입니다. 개발 서버의 Ngin…","fields":{"slug":"/how-to-use-nginx/"},"frontmatter":{"date":"August 01, 2023","title":"괜찮을지도의 Nginx 활용법","tags":["인프라"]},"rawMarkdownBody":"\n> 이 글은 우아한테크코스 괜찮을지도팀의 `도이`가 작성했습니다.\n\n지난 글 [GitHub Actions로 CI/CD 구축하기](https://map-befine-official.github.io/github-actions-ci-cd)에서  \n현재 저희 프로젝트의 인프라 구조를 간략하게 이미지로 설명드렸습니다.\n\n다시 이미지를 보여드리자면, 서버의 앞단에서 Nginx를 사용하고 있는데요.\n\n![infra_nginx.png](.index_image/infra_nginx.png)\n> ⚠️ 편의상 개발 서버, DB 서버 부분은 생략하고 확대한 이미지입니다.  \n> 개발 서버의 Nginx도 같은 역할을 수행합니다.  \n> 또, 80 포트 요청에 대해서도 443 포트로 리다이렉트해주고 있으나 이 또한 편의상 그림에는 생략하고 있습니다.  \n \n이번 글에서는 Nginx의 모든 것에 대해 설명하기보다는 Nginx를 왜 썼는지, 어떻게 썼는지에 초점을 맞춰보도록 하겠습니다.  \n\n## Nginx란?\n그래도 이게 뭔지 알아야겠죠? 간단하게 설명하면, 경량화된 웹 서버 프로그램입니다.  \n정적 파일을 제공하는 HTTP 서버로도, 리버스 프록시 서버로도 사용할 수 있습니다.  \n\n이제 저희의 Nginx 설정 파일을 보면서 어떻게 활용했는지 설명드리겠습니다.\n\n> 설정 파일은 과거 방식으로는 /etc/nginx/sites-available 또는 /sites-enabled에서 관리하고,  \n> 최신 방법으로는 /etc/nginx/conf.d 디렉토리에서 관리합니다.  \n> 또, 전역 설정을 관리하는 파일로는 `/etc/nginx/nginx.conf`가 있습니다.\n```properties\nserver {\n        # (1) HTTPS 적용 전, 서버 이름 지정\n        server_name ${도메인};\n\n        # (1) HTTPS 적용 : SSL을 사용하여 443포트에서 수신\n        listen 443 ssl; # managed by Certbot\n        ssl_certificate /etc/letsencrypt/live/${도메인}/fullchain.pem; # managed by Certbot\n        ssl_certificate_key /etc/letsencrypt/live/${도메인}/privkey.pem; # managed by Certbot\n        include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n        ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n        # (3) 웹 서버의 루트 디렉토리 지정\n        root /var/www/html;\n\n        # (3) 웹 서버가 디렉토리를 열 때 사용할 기본 파일 지정 (나열된 순서대로 탐색)\n        index index.html index.htm index.nginx-debian.html;\n\n        # (2, 3) 루트 URL에 대한 동작 정의 : 프론트엔드 정적 파일 서브\n        location / {\n            root /usr/share/nginx/html/dist;\n            include /etc/nginx/mime.types;\n            try_files $uri $uri/ /index.html;\n        }\n\n        # (2) /api/ URL에 대한 동작 정의 : 백엔드 API 연결\n        location /api/ {\n            rewrite ^/api/(.*) /$1?$args break;\n            proxy_pass http://${서버 IP 주소}:8080;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        }\n}\n\n# 해당 도메인에 대해 80번 포트 HTTP 요청이 오면 HTTPS로 리다이렉션\nserver {\n    if ($host = ${도메인}) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n    \n    \n    listen 80 ;\n    listen [::]:80 ;\n    server_name ${도메인};\n}\n```\n\n## (1) HTTPS 적용하기\nSSL 인증서만 있으면, 웹서버를 통해 쉽게 HTTPS 프로토콜을 적용할 수 있습니다.  \n무료 이용이 가능하고, `Nginx`와 통합하여 사용하기 좋은 `Certbot`을 사용해 이를 적용했습니다.  \n전체적인 흐름은 아래와 같습니다.  \n\n1. 도메인을 구매하고, 레코드 A에 public IP 주소를 등록한다.\n2. `Cerbot`을 설치한다.\n3. 설정 파일의 server_name을 구매한 도메인으로 변경한다.\n4. `Certbot`을 이용해 구매한 도메인을 이용해 SSL 인증서를 발급받는다.\n5. 인증서를 발급받으면, `Certbot`이 자동으로 설정 파일에서 server_name이 일치하는 블록을 찾아 SSL 관련 내용들을 추가해준다.\n\n`# managed by Certbot`이라는 주석이 붙어있는 내용들이 `Certbot`이 추가해준 내용입니다.\n\n> `Certbot`은 SSL 인증 발급 도구로, 무료 SSL 인증서 발급 기관인 `Let's Encrypt`와 통합되어 있습니다.  \n> 이를 통해 쉽게 SSL 인증서를 발급받을 수 있습니다.  \n> 또, `Nginx` 설정 파일을 자동 업데이트하는 방식으로 SSL 인증서를 적용할 수 있어 편리합니다.\n> 단, 유효 기간이 90일이기 때문에 자동 갱신 설정이 별도로 필요합니다.  \n\n하단에 첨부한 참고 자료와 같이, 잘 정리된 자료가 기존에 많기 때문에 자세한 내용은 생략하겠습니다.\n\n## (2) 프론트엔드, 백엔드 요청 구분하기\n저희 프로젝트의 인프라 구조에서는 프론트엔드와 백엔드가 같은 서버를 공유하므로  \n클라이언트가 이용하는 화면에 대한 요청과, 백엔드 API에 대한 요청을 구분할 필요가 있었습니다.  \n\n`location` 블록을 사용해 특정 URL에 대한 동작을 설정하는 방식으로 이를 구분할 수 있었습니다.  \n\n해당하는 부분을 가져와 설명드리겠습니다.\n```properties\n# 루트 URL에 대해 프론트엔드 정적 파일 서브\nlocation / {\n    root /usr/share/nginx/html/dist;\n    include /etc/nginx/mime.types;\n    try_files $uri $uri/ /index.html;\n}\n\n# /api/ URL에 대해 백엔드 API 연결\nlocation /api/ {\n    rewrite ^/api/(.*) /$1?$args break; # URL에서 /api 제거\n    proxy_pass http://${서버 IP 주소}:8080;\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n}\n```\n\n`https://mapbefine.com/api/` 로 시작하는 URL에 대해서는 백엔드 API와 연결합니다.  \n\n이 설정을 맞추어, 백엔드 코드에서 `/api`가 추가된 요청 URL을 매핑할 수도 있습니다.  \n하지만 이는 자원을 명시하기 위한 내용보다는 요청을 구분하기 위함이므로,  \n리버시 프록시를 거치고 나면 실제로는 `/api`를 제외한 요청 URL로 연결되도록 하였습니다.  \n`# URL에서 /api 제거` 주석이 있는 부분이 해당하는 내용입니다.  \n\n> `proxy_set_header`는 Nginx가 프록시 요청을 전달하기 전에, HTTP 요청 헤더를 설정하는 지시문입니다.  \n> 원래 요청의 호스트 이름을 백엔드 서버에 전달합니다.  \n> 필수 설정은 아니지만 IP 기반의 접근 제어, 로깅, 다중 호스트 설정 등에 유용할 수 있다고 합니다.  \n\n## (3) 정적 파일 서브하기\n저희는 프론트엔드의 React를 서버에서 실행시키는 대신, 빌드 결과물을 정적 파일로 서브하는 방식을 택하였습니다.  \n이유는 다음과 같습니다.  \n1. 어플리케이션을 서버 내에 실행하여 동적으로 파일을 생성해야 하는 상황이 아닙니다.\n2. 정적 파일로 서브하여 서버 메모리를 절약할 수 있습니다.\n\n어플리케이션을 실행시킨 상태라면, 해당하는 URL에 대해 3000번 포트로 포워딩해주면 됩니다.\n\n반면 정적 파일로 서브한다면 어떻게 해야 할요?  \n해당하는 부분을 가져와 설명드리겠습니다.\n\n아래 내용은 설정 파일의 기본 값과 같습니다.\n```properties\n# (3) 웹 서버의 루트 디렉토리 지정\nroot /var/www/html;\n\n# (3) 웹 서버가 디렉토리를 열 때 사용할 기본 파일 지정 (나열된 순서대로 탐색)\nindex index.html index.htm index.nginx-debian.html;\n```\n\n`https://mapbefine.com` 요청이 들어오면, Nginx는 루트 디렉토리의 `index.html`을 우선적으로 찾아 반환합니다.  \n따라서 해당 웹 서버의 루트 디렉토리에 우리의 빌드 결과물인 `index.html`와 모듈 파일들을 위치시키면 됩니다.  \n반대로, 정적 파일을 저장하고 있는 위치를 root 값으로 설정해주어도 좋습니다.\n \n## 결론\n괜찮을지도 서버의 Nginx는  \n클라이언트와 WAS(Spring Boot) 사이에 Nginx를 두어 리버스 프록시 서버로 사용하며,  \n동시에 HTTPS 적용을 해결하고 HTTP 서버와 같이 정적 파일 서브도 수행하고 있습니다.\n\n다만 현재 규모에서 간단한 방법을 택한 것으로,  \n서비스의 규모가 커짐에 따라 정적 파일을 별도 서버에 관리하는 것이 유리하거나 동적인 파일 생성이 필요한 경우 활용 방식은 얼마든지 달라질 수 있을 것입니다.\n\n\n## 참고자료\n[Nginx 공식 문서](https://nginx.org/en/docs/)  \n[baledung - sites-available & sites-enabled, conf.d 설정 파일 방식 차이](https://www.baeldung.com/linux/sites-available-sites-enabled-conf-d)  \n[Nginx와 Let's Encrypt로 HTTPS 웹 서비스 배포하기 (feat. Certbot)](https://hudi.blog/https-with-nginx-and-lets-encrypt/)  \n[how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-22-04 (Step2 부분 참고)](https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-22-04)\n"},{"excerpt":"이 글은 우아한테크코스 괜찮을지도팀의 가 작성했습니다I 테스트 간 격리.. 왜 필요할까? 우리는 프로덕션 코드의 신뢰성을 보장하기 위해서 테스트 코드를 작성한다. 그렇기 때문에, 테스트 코드는 100번을 실행시키던 100만번을 실행시키던, 동일한 결과를 내뱉어야한다. 테스트 코드를 아무리 잘 작성하더라도, 매번 테스트의 결과가 다르다면 의미가 없다. 예를…","fields":{"slug":"/how-to-isolating-test/"},"frontmatter":{"date":"July 31, 2023","title":"인수테스트에서 테스트 격리하기!","tags":["테스트","데이터베이스"]},"rawMarkdownBody":"\n> 이 글은 우아한테크코스 괜찮을지도팀의 `매튜`가 작성했습니다I\n\n## 테스트 간 격리.. 왜 필요할까?\n\n우리는 프로덕션 코드의 신뢰성을 보장하기 위해서 테스트 코드를 작성한다.\n\n그렇기 때문에, 테스트 코드는 100번을 실행시키던 100만번을 실행시키던, 동일한 결과를 내뱉어야한다.\n\n테스트 코드를 아무리 잘 작성하더라도, 매번 테스트의 결과가 다르다면 의미가 없다.\n\n예를 들어 아래와 같은 테스트가 있다고 해보자.\n\n```java\n@DataJpaTest\npublic class ExampleTest {  \n\n    @Autowired  \n    private PinRepository pinRepository;  \n      \n    @Test  \n    void 모든_핀을_조회한다() {  \n        // given  \n        Pin pin = new Pin(...);  \n        pinRepository.save(pin);  \n          \n        // when  \n        List<Pin> pins = pinRepository.findAll();  \n  \n        // then  \n        assertAll(  \n                () -> assertThat(pins).hasSize(1),  \n                () -> assertThat(pins.get(0)).isEqualTo(pin)  \n        );  \n    }  \n\n}\n```\n\n정상적인 경우라면, 위 테스트는 통과해야한다.\n\n하지만, 테스트 간 격리를 진행하지 않은 상태에서 이 테스트 이전에 다른 테스트에서 pin 을 저장하는 동작을 수행했고, 데이터를 지워주지 않았다면?\n\n해당 테스트는 실패하게 될 것이다.\n\n위 테스트는 이전에 수행된 테스트들의 동작에도 영향을 받는, 독립적이지 못한 테스트가 된 것이다.\n\n이것이 바로 테스트 간 격리가 필요한 이유이다.\n\n그렇다면 위와 같은 상황을 @Transactional 어노테이션만으로 완벽하게 예방할 수 있을까?\n\n결론부터 말하자면 그럴 수 없다.\n\n@SpringBootTest 를 사용하는 인수테스트 같은 경우는 Port 를 지정하여 서버를 띄우게 되는데, 이 때 HTTP 클라이언트와 서버는 각기 다른 스레드에서 실행되게 된다.\n\n그렇기 때문에 테스트 코드에 @Transactional 있더라도 호출되는 쪽은 다른 스레드에서 새로운 트랜잭션을 커밋하기 때문에, 롤백 전략은 무색해지게 되고, 테스트 간 격리도 제대로 이행될 수가 없는 것이다.\n\n## 그렇다면 격리를 위해 사용할 수 있는 방법들은 무엇이 있을까?\n\n이번 포스트를 통해서 다뤄볼 방법은 3가지이다.\n\n바로 `Dirtiest Context`,  `@Sql 어노테이션`, `Entity Manager` 이다.\n\n하나씩 짚어보면서 넘어가보자.\n\n### DirtiesContext\n\n```java\n@DirtiesContext(classMode = DirtiesContext.ClassMode.BEFORE_EACH_TEST_METHOD)  \n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)\npublic class ExampleTest {\n\t...\n}\n```\n\n`DiriesContext` 는 현재 테스트를 실행하고자 하는 컨텍스트에 빈이 로드되어 있으면 Dirties 를 확인하고 Bean 들을 Reload 하게 된다.\n\n즉, 테이블도 다시 만들기 때문에 테스트 간의 격리가 가능하다.\n\n하지만, 매번 테스트하기 이전에 컨텍스트를 Reload 하게 된다면, 테스트 시간은 한없이 길어지게 될 것이기 때문이다.\n\n테스트의 장점은 프로덕션 코드의 신뢰성을 보장함에도 존재하지만, 개발자가 개발을 진행중에 코드를 올바르게 작성중인지 바로 바로 응답받기 위한 수단이기도 하다.\n\n따라서, 응답 속도는 개발 진행 속도와 크게 연관되어 있는 것이다.\n\n하지만, 인수테스트에 DirtiesContext 를 난사하게 되면, 매 테스트 실행마다 속이 터지는 경험을 하게 될 것이다.\n\n### @Sql 어노테이션\n\n해당 방법은 꽤나 획기적인 방법이다.\n\n간단한 sql 구문만으로 테스트 간의 격리를 이뤄낼 수 있다. \n\n어떤 이는 외래키 제약 조건으로 인해 한번에 데이터를 삭제하는 것이 불가능하다고 생각할 수도 있지만, 아래 코드와 같이 외래키 제약 조건을 해제해주고 데이터를 삭제하는 것이 가능하다. \n\n```sql\nSET FOREIGN_KEY_CHECKS = 0;  \nTRUNCATE TABLE 테이블이름;  \n...\nSET FOREIGN_KEY_CHECKS = 1;\n```\n\n```java\n@DataJpaTest\n@Sql(\"/truncate.sql\")\npublic class ExampleTest {  \n\t...\n}\n```\n\n하지만, 해당 방법에도 단점은 존재한다.\n\n바로, 테이블이 추가될 때마다, 해당 sql 구문을 수정해주어야 한다는 것이다.\n\n큰 단점은 아니지만, 항상 신경써주어야 한다는 점에서 조금은 아쉽다는 생각이 든다. \n\n### Entity Manager\n\n위에서도 언급하였듯 `@Sql` 어노테이션은 정말 강력하지만, 테이블이 추가될 때마다 sql 구문을 다시 수정해주어야 한다는 단점이 존재했다.\n\n이 때, `@Sql` 어노테이션의 장점을 모두 가져가면서, 위에서 언급한 단점도 보완할 수 있는 방법이 있다.\n\n바로 `Entity Manager` 를 활용하는 방법이다.\n\n도대체 어떻게? `Entity Manager` 를 통해서 Data 를 지운다는 것일까?\n\n우리는 개발자이니 코드를 통해 살펴보자. \n\n```java\n@Componenet  \npublic class DatabaseCleanup implements InitializingBean {  \n\n\tprivate static final String UNDERSCORE = \"_\";\n  \n    @PersistenceContext  \n    private EntityManager entityManager;  \n  \n    private List<String> tableNames;  \n  \n    @Override  \n    public void afterPropertiesSet() {  \n        tableNames = entityManager.getMetamodel().getEntities().stream()  \n                .filter(entityType -> entityType.getJavaType().getAnnotation(Entity.class) != null)  \n                .map(entityType -> convertTableNameFromCamelCaseToSnakeCase(entityType.getName()))  \n                .toList();  \n    }  \n\n    private String convertTableNameFromCamelCaseToSnakeCase(String tableName) {  \n        StringBuilder tableNameSnake = new StringBuilder();  \n  \n        for (char letter : tableName.toCharArray()) {  \n            addUnderScoreForCapitalLetter(tableNameSnake, letter);  \n            tableNameSnake.append(letter);  \n        }  \n  \n        return tableNameSnake.substring(1).toLowerCase();  \n    }  \n  \n    private void addUnderScoreForCapitalLetter(StringBuilder tableNameSnake, char letter) {  \n        if (Character.isUpperCase(letter)) {  \n            tableNameSnake.append(UNDERSCORE);  \n        }  \n    }  \n  \n}\n```\n\nEntity Manager 를 통해 데이터를 관리하기 위해 DatabaseCleanup 이라는 객체를 생성해줬다.\n\n`InitializingBean` 을 implements 해 `afterPropertiesSet` 메서드를 구현하게되면, 프로퍼티가 모두 초기화되었을 때, BeanFactory에 의해 자동으로 해당 메서드가 호출되게 된다.\n\n그러니, 해당 메서드의 내부 구현으로 Entity 들의 ClassName 을 이용하여 모든 테이블명을 생성해내어 저장하면 된다. (Entity Class 명을 Camel Case -> Snake Case 로 변환해준다. `convertTableNameFromCamelCaseToSnakeCase` 가 해당 동작을 수행해주고 있다.)\n\n위와 같이 모든 테이블명을 생성해내어 저장했다면, 해당 테이블 명들을 이용하여 Data 를 모두 지워주는 execute 를 구현해주자.\n\n```java\n@Service  \npublic class DatabaseCleanup implements InitializingBean {  \n\n\tprivate static final String SET_REFERENTIAL_INTEGRITY_SQL_MESSAGE = \"SET REFERENTIAL_INTEGRITY %s\";  \n\tprivate static final String TRUNCATE_SQL_MESSAGE = \"TRUNCATE TABLE %s\";  \n\tprivate static final String ID_RESET_SQL_MESSAGE = \"ALTER TABLE %s ALTER COLUMN ID RESTART WITH 1\";  \n  \n    @PersistenceContext  \n    private EntityManager entityManager;  \n  \n    private List<String> tableNames;  \n\n\t...\n\n\t@Transactional  \n\tpublic void execute() {  \n\t    entityManager.flush();  \n\t    entityManager.createNativeQuery(String.format(SET_REFERENTIAL_INTEGRITY_SQL_MESSAGE, false)).executeUpdate();  \n\t  \n\t    for (String tableName : tableNames) {  \n\t        entityManager.createNativeQuery(String.format(TRUNCATE_SQL_MESSAGE, tableName)).executeUpdate();  \n\t        entityManager.createNativeQuery(String.format(ID_RESET_SQL_MESSAGE, tableName)).executeUpdate() ;  \n\t    }  \n\t  \n\t    entityManager.createNativeQuery(String.format(SET_REFERENTIAL_INTEGRITY_SQL_MESSAGE, true)).executeUpdate();  \n\t}\n\t  \n}\n```\n\n위의 코드를 순서대로 간단하게 설명해보자면\n\n1. 외래키 제약조건을 비활성화 해준다. \n2. `afterPropertiesSet` 을 통해 생성해놓은 모든 테이블 명들을 이용하여 Data 들을 모두 Truncate 해주고, ID 값을 다시 세팅해준다.\n3. 외래키 제약조건을 활성화해준다. \n\n이런 Flow 로 흘러가는 execute 메서드를 구현해주었다면\n\n```java\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)  \npublic class ExampleTest {  \n  \n    @LocalServerPort  \n    private int port;  \n  \n    @Autowired  \n    private DatabaseCleanup databaseCleanup;  \n  \n    @BeforeEach  \n    public void setUp() {  \n        RestAssured.port = port;  \n    }  \n  \n    @AfterEach  \n    public void tearDown() {  \n        databaseCleanup.execute();  \n    }  \n  \n}\n```\n\n위 코드와 같이 @AfterEach 를 통해 매 인수테스트 동작 이후 실행시켜주면, 모든 테스트들을 격리할 수 있게 되는 것이다.\n\n\n## 결론\n\n지금으로서는 데이터 삭제가 쉽고, 테이블이 추가되었을 때 sql 구문을 수정하지 않아도 되는 `Entity Manager` 를 통해 테스트를 격리하는 것이 최선의 방법으로 보인다.\n\n하지만, 추후에 이보다 더 좋은 방법을 발견하면, 면밀히 검토해보고 바꿀 의사가 충분하다고 생각한다.\n\n## 참고\n\nhttps://tecoble.techcourse.co.kr/post/2020-09-15-test-isolation/\n"},{"excerpt":"이 글은 우테코 괜찮을지도의 가 작성하였습니다. 배경 괜찮을지도 서비스는 CI/CD 툴로 Github Actions를 적용하였습니다.\n 자세한 내용이 궁금하다면 ? 괜찮을지도 CI/CD 구축기 바로가기 프로젝트의 설정 파일(.yml)은 DB 주소 등 민감한 정보를 담고 있었기 때문에, 이를 저장소에 그대로 업로드할 수 없었습니다.\n위 문제점을 해결하기 위…","fields":{"slug":"/trouble-shooting-actions-runner/"},"frontmatter":{"date":"July 31, 2023","title":"EC2 환경 변수 적용 및 Actions Runner에 환경 변수 적용이 안되는 이슈","tags":["인프라","Actions Runner"]},"rawMarkdownBody":"\n> 이 글은 우테코 괜찮을지도의 `쥬니`가 작성하였습니다.\n\n### 배경\n\n괜찮을지도 서비스는 CI/CD 툴로 Github Actions를 적용하였습니다.\n<br> 자세한 내용이 궁금하다면 ? [괜찮을지도 CI/CD 구축기 바로가기](/contents/posts/github-actions-ci-cd/index.md)\n\n프로젝트의 설정 파일(.yml)은 DB 주소 등 민감한 정보를 담고 있었기 때문에, 이를 저장소에 그대로 업로드할 수 없었습니다.\n<br>위 문제점을 해결하기 위한 과정과 실제 우리가 직면한 문제를 설명해 드리고자 합니다.\n\n### 환경변수 적용\n괜찮을지도는 환경 변수를 활용하여 민감한 정보를 숨기기로 했습니다.\n이에 따라, 각 배포 환경(prod, dev)에 맞는 설정 파일을 아래와 같이 작성하였습니다.\n```yaml\n# `application-dev`의 일부 \nspring:\n  datasource:\n    driver-class-name: com.mysql.cj.jdbc.Driver\n    url: ${MYSQL_DATABASE_URL} \n    username: ${MYSQL_DATABASE_USER_NAME}\n    password: ${MYSQL_DATABASE_PASSWORD}\n```\n설정 파일에서 사용한 환경 변수는 각 EC2 인스턴스에서 관리하도록 하였습니다.\n<br>EC2 인스턴스에 환경변수를 적용하는 방법은 아래와 같습니다.\n\n`1. EC2 터미널에 접속한다.`\n\n`2. 'sudo vim ~/.bashrc' 명령어를 입력한다.`\n\n`3. .bashrc 파일의 맨 아래에 아래와 같이 필요한 환경변수를 입력한 뒤, 저장한다.`\n```shell\n# ...\n# 기존 .bashrc 코드 생략 \n#\n# Database\nexport profile='dev'\nexport MYSQL_DATABASE_URL='Database url'\nexport MYSQL_DATABASE_USER_NAME='User name'\nexport MYSQL_DATABASE_PASSWORD='Password'\n```\n\n`4. 'source ~/.bashrc' 명령어를 입력하여 환경변수를 업데이트해 준다.`\n\n`5. 'echo $profile' 명령어를 입력하여 환경변수가 적용되었는지 확인한다.`\n\n### 환경 변수가 Actions Runner 동작에 적용되지 않는 이슈\n\n우리는 위 과정을 통해, 환경 변수가 EC2에 올바르게 적용된 것을 확인했습니다.\n<br>실제로, 아래와 같은 명령어를 통해 어플리케이션을 실행할 경우 `profile`로 설정한 환경변수인 dev가 올바르게 적용되는 것을 확인할 수 있었습니다.\n```shell\n# $JAR_FILE_PATH는 'deploy.sh' 파일 내에 존재하는 jar 파일의 경로를 나타내는 변수입니다.\nnohup sudo -E java -jar $JAR_FILE_PATH/mapbefine.jar --spring.profiles.active=$profile >> $JAR_FILE_PATH/deploy.log 2> $JAR_FILE_PATH/deploy-err.log &\n```\n![](.index_image/active-profile-dev.png)\n\n하지만, Actions Runner를 통해 CD를 수행하는 경우 아래와 같이 환경 변수가 적용되지 않았습니다.\n![](.index_image/active-profile-default.png)\n\n### 원인 및 문제 해결\n우리는 위 문제를 해결하기 위해, 아래와 같이 우리의 상황을 정리하였습니다.\n1. 터미널에서 쉘 스크립트를 실행할 경우, 환경 변수가 적용된다.\n2. Actions Runner를 통해 쉘 스크립트를 실행할 경우, 환경변수가 적용되지 않는다.\n3. CI/CD를 구축한 뒤에 환경 변수를 적용했다.\n\n위 상황을 통해, 우리는 환경 변수를 적용하기 전, 이미 실행되고 있었던 Actions Runner에 환경변수가 적용되지 않았음을 직감할 수 있었습니다.\n<br>실제로, 환경 변수는 프로세스가 시작될 때 해당 프로세스에게 제공되는 환경 설정의 일부이기 때문에, 위와 같은 문제가 발생한 것이었습니다.\n\n기존에 실행되고 있었던 Actions Runner 프로세스를 종료한 후, 재시작을 하였고 환경 변수가 올바르게 적용되는 것을 확인할 수 있었습니다.\n"},{"excerpt":"이 글은 우테코 괜찮을지도팀의 가 작성했습니다. 보다 편리하고 안정적인 개발 및 배포를 위해, 괜찮을지도 서비스에 CI/CD를 적용하였습니다. 이를 위한 도구로 GitHub Actions(self hosted runner)를 선택한 이유와, 파이프라인, 적용 방법에 대해 설명드리겠습니다. GitHub Actions를 사용한 이유 먼저 저희의 상황을 설명드…","fields":{"slug":"/github-actions-ci-cd/"},"frontmatter":{"date":"July 29, 2023","title":"GitHub Actions로 CI/CD 구축하기","tags":["인프라"]},"rawMarkdownBody":"\n> 이 글은 우테코 괜찮을지도팀의 `도이`가 작성했습니다.\n\n보다 편리하고 안정적인 개발 및 배포를 위해, 괜찮을지도 서비스에 CI/CD를 적용하였습니다.  \n이를 위한 도구로 GitHub Actions(self hosted runner)를 선택한 이유와, 파이프라인, 적용 방법에 대해 설명드리겠습니다.\n\n## GitHub Actions를 사용한 이유\n\n먼저 저희의 상황을 설명드리자면, \n아래와 같은 제약 사항 안에서 개발 서버, 운영 서버의 분리가 필요했습니다.\n\n### 제약 사항\n- EC2 최대 3개\n- 최대 t4g.small\n- 최대 20GiB\n- 매모리 2GiB\n\n운영 서버에서 사용하는 DB는 서버 분리가 필요하다고 판단해, 세 대의 인스턴스를 각각 아래 그림과 같이 개발, 운영, 운영 DB 서버로 분담했습니다.  \n그리고 이 제약 사항 안에서 알뜰하게 서버를 사용하고 트러블 슈팅하는 것을 저희의 기술적 도전으로 삼고자 합니다.\n\n### 인프라 구조\n![](.index_image/infra.jpeg)\n \n팀원들 모두가 CI/CD에 능숙하지 않은 상황에서 상대적으로 대중적이고 관련 자료를 쉽게 접할 수 있는 기술을 생각했을 때,  \nJenkins와 GitHub Actions가 고려 대상이었습니다.\n\n아래와 같은 이유로, 둘 중 GitHub Actions를 사용해 최대한 간단하게 CI/CD를 구축하는 것이 적합하다고 판단했습니다.  \n\n1. 메모리 부담 최소화\n   - Jenkins를 사용하면, EC2에서 빌드 및 테스트를 수행해야 합니다.\n   - 반면, GitHub Actions는 GitHub Artifact에 업로드한 빌드 결과물을 EC2에서 다운로드하면 됩니다.\n   - 실제로 한 팀원이 EC2 t2g.micro에 젠킨스 CI/CD를 적용했다가, 메모리가 부족해 서버가 죽는 과거의 경험을 공유해주었습니다.\n   - 때문에 적어도 CI 만큼은 GitHub Actions로 분리해 테스트 실행을 외부 서비스에 위임하기로 했습니다.\n   - 하지만 그렇다면, 간결한 파이프라인을 위해 CI/CD를 모두 GitHub Actions로 통합하는 것이 좋다고 판단했습니다.\n   > EC2에서 `./gradlew build`를 수행해 직접 빌드 및 테스트를 할 경우 아래와 같이 총 26.2%의 사용량이 확인되지만,  \n   ![ec2-build-usage.png](.index_image/ec2-build-usage.png)\n   > 그 대신 Actions Runner가 가동하는 상황을 확인해본 결과, 전체 메모리의 최대 11.9%만을 사용함을 알 수 있었습니다.   \n   ![actions-runner-usage.png](.index_image/actions-runner-usage.png)\n   \n    \n2. 쉽고 빠른 적용 \n   - GitHub 레포지토리에서 바로 설정이 가능해 기존 개발 환경과 통합해 사용 가능합니다.\n   - YAML 파일 작성만으로도 쉽고 빠른 적용이 가능합니다.\n   - GitHub가 Runner를 관리해주기 때문에, 서버 관리 부담이 덜합니다.\n  \n  \n## CI/CD 파이프라인\n![](.index_image/cicd-pipeline.jpeg)\nCI/CD 파이프라인은 다음과 같습니다.  \n1. Pull Request의 생성 또는 업데이트, Pull Request에 대한 Merge가 발생합니다.\n2. 이벤트에 트리거된 `GitHub Actions workflow`가 실행됩니다.\n3. `workflow`에 작성한 내용에 의해, `GitHub hosting Runner`가 빌드 및 테스트를 수행합니다.\n   - 이 때, 테스트 결과를 PR 코멘트로 등록해줍니다.\n   - `Pull Request의 생성 또는 업데이트에 대한 workflow`의 경우 이 단계까지만 수행합니다.\n4. `Pull request Merge에 대한 workflow`의 경우, 빌드한 결과물을 GitHub의 자체 저장소인 `Artifact Storage`에 업로드합니다.\n5. 우리의 `EC2`에 설치된 `Self Hosted Runner`가 4번의 결과물을 다운로드 받습니다.\n6. `Self Hosted Runner`가 배포 스크립트를 실행하게 하여, 필요한 어플리케이션을 실행하고 정적 파일을 적절한 위치에 배치합니다.\n\n2번부터 6번까지, 모두 하나의 workflow 내에서 벌어지는 일입니다.\n\n## 적용 방법\n\n### GitHub Actions workflow\n`workflow`란 하나 이상의 작업을 실행하는, 자동화된 프로세스입니다.  \n레포지토리의 `.github/workflows` 디렉토리에 YAML 파일을 저장해 `workflow` 를 정의할 수 있습니다.\n하나의 레포지토리는 여러 개의 `workflow`를 가질 수 있습니다.\n\n괜찮을지도 서비스에서는\n1. `pull request`에 대한 빌드 및 테스트만 수행하는 상황 vs `pull request merge` 시 배포까지 수행하는 상황\n2. 대상이 `main` 브랜치 vs `dev` 브랜치\n3. 대상이 프론트엔드 / 백엔드\n\n세 가지 상황을 고려하여 여러 개의 `workflow`를 작성했습니다.  \n\n![](.index_image/workflows-dev.jpeg)\n![](.index_image/workflows-prod.jpeg)\n\n### workflow 만들기\n`workflow`는 기본적으로 아래와 같은 요소들을 가져야 합니다.\n1. `workflow`를 유발시킬 하나 이상의 이벤트 : `on`\n2. `workflow`에서 수행할 하나 이상의 작업: `job`\n3. `job` 블록 내에 단계 별 스크립트 또는 익스텐션 실행을 정의: `step`\n\n여기서 주의할 점은, 여러개의 `job`은 기본적으로 병렬적으로 처리된다는 것입니다.  \n순차적으로 실행하고 싶다면, `needs` 블록을 사용해야 합니다.  \n\n\n아래는 현재 적용된 workflow입니다. 이해를 돕기 위해 주석을 추가하였습니다.  \n### 백엔드 CI workflow\n```yaml\nname: Backend CI For Test Validation\n\n# 트리거 설정\non:\n  workflow_dispatch:\n  \n  pull_request:\n    branches: [ main, develop ]\n    paths: backend/** # 해당 디렉토리 내 파일의 변경이 있을 때만 트리거됨\n\n# 테스트 결과 등록을 위한 권한 설정\npermissions: \n  pull-requests: write\n  checks: write\n  contents: write\n  \n# 수행할 작업들\njobs:\n  build-and-comment:\n    # 해당 job을 실행할 환경 설정\n    runs-on: ubuntu-22.04\n\n    steps:\n    - uses: actions/checkout@v3\n    - name: Set up JDK 17\n      uses: actions/setup-java@v3\n      with:\n        java-version: '17'\n        distribution: 'temurin'\n        \n    - name: gradlew 실행 권한 부여\n      run: chmod +x gradlew\n      working-directory: backend\n\n    - name: Gradle build 시작\n      run: ./gradlew clean build\n      working-directory: backend\n\n    - name: 테스트 결과를 PR에 코멘트로 등록합니다\n      uses: EnricoMi/publish-unit-test-result-action@v1\n      if: always()\n      with:\n        files: 'backend/build/test-results/test/TEST-*.xml'\n\n    - name: 테스트 실패 시, 실패한 코드 라인에 Check 코멘트를 등록합니다\n      uses: mikepenz/action-junit-report@v3\n      if: always()\n      with:\n        report_paths: '**/build/test-results/test/TEST-*.xml'\n        token: ${{ github.token }}\n```\n\n### 백엔드 CD workflow\n```yaml\nname: Backend develop CI/CD\n\non:\n  workflow_dispatch:\n  \n  pull_request:\n     # 배포 설정은 main, develop 브랜치 별로 다르게 트리거\n    branches: [ develop ]\n     # 브랜치가 닫힐 때만 트리거\n    types: [closed]\n    paths: backend/**\n\npermissions:\n  contents: read\n  \njobs:\n  build-and-upload:    \n    # Pull Request를 그냥 닫은 게 아니라, merge해서 닫았을 때만 실행\n    if: github.event.pull_request.merged\n    \n    runs-on: ubuntu-22.04\n\n    steps:\n    - uses: actions/checkout@v3\n    - name: Set up JDK 17\n      uses: actions/setup-java@v3\n      with:\n        java-version: '17'\n        distribution: 'temurin'\n        \n    - name: gradlew 실행 권한 부여\n      run: chmod +x gradlew\n      working-directory: backend\n\n    - name: Gradle build 시작\n      run: ./gradlew clean build\n      working-directory: backend\n        \n    - name: jar 파일 artifact에 업로드\n      uses: actions/upload-artifact@v3\n      with:\n        name: BackendApplication\n        path: backend/build/libs/mapbefine.jar\n\n  deploy:\n     # Pull Request를 그냥 닫은 게 아니라, merge해서 닫았을 때만 실행\n     if: github.event.pull_request.merged\n\n     # deploy는 build-and-upload 작업과 달리 self-hosted runner를 사용\n     # main, develop 브랜치마다 각각 운영 서버, 개발 서버의 runner만을 실행하도록 해야 함\n     runs-on: [ self-hosted, dev ]를\n     # build-and-upload 작업이 성공적으로 완료될 경우 실행\n     needs: build-and-upload\n  \n     steps:\n      - name: 구버전 jar 파일 삭제\n        run: rm -rf /home/ubuntu/backend/build/*.jar \n\n      - name: jar파일 artifact에서 다운로드\n        uses: actions/download-artifact@v3 \n        with:\n          name: BackendApplication\n          path: /home/ubuntu/backend/build/\n\n      - name: 배포하기\n        run: /home/ubuntu/backend/deploy.sh\n\n      - name: 슬랙 메시지 보내기\n\n        uses: 8398a7/action-slack@v3\n        with:\n          mention: 'here'\n          if_mention: always\n          status: ${{ job.status }}\n          fields: workflow,job,commit,message,ref,author,took\n        env:\n          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}\n        if: always()\n```\n\n### 프론트엔드 CI workflow\n```yaml\nname: Frontend CI For Test Validation\n# 어떤 이벤트가 발생하면 실행할지 결정\non:\n  #pull request open과 reopen 시 실행한다.\n  pull_request:\n    branches: [main, develop]\n    paths: frontend/**\ndefaults:\n  run:\n    working-directory: ./frontend\njobs:\n  jest:\n    runs-on: ubuntu-22.04\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v2\n        with:\n          node-version: \"18\"\n\n      - name: Install node modules\n        run: npm install\n\n      - name: Run Jest test\n        run: npm run test\n```\n\n### 프론트엔드 CD workflow\n```yaml\nname: Frontend develop CD\n\non:\n  workflow_dispatch:\n\n  pull_request:\n    branches: [ develop ]\n    types: [ closed ]\n    paths: frontend/**\n\npermissions:\n  contents: read\n\njobs:\n  build-and-upload:\n    if: github.event.pull_request.merged\n\n    runs-on: ubuntu-22.04\n\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Node.js 18\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n          cache: \"npm\"\n\n      - name: Install npm\n        run: npm install --force\n\n      - name: grant excute access\n        run: chmod +x npm\n\n      - name: Build project\n        run: npm run build\n\n      - name: upload to artifact\n        uses: actions/upload-artifact@v3\n        with:\n          name: FrontendApplication\n          path: frontend/dist\n\n  deploy:\n      runs-on: [ self-hosted, dev ]\n      needs: build-and-upload\n\n      if: github.event.pull_request.merged\n\n      steps:\n        - name: delete old js file\n          run: rm -rf /home/ubuntu/frontend/dist\n\n        - name: download js file from artifact\n          uses: actions/download-artifact@v3\n          with:\n            name: FrontendApplication\n            path: /home/ubuntu/frontend\n\n        - name: deploy\n          run: /home/ubuntu/frontend/deploy.sh\n\n        - name: send slack message\n\n          uses: 8398a7/action-slack@v3\n          with:\n            mention: 'here'\n            if_mention: always\n            status: ${{ job.status }}\n            fields: workflow,job,commit,message,ref,author,took\n          env:\n            SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}\n          if: always()\n\n```\n\n## Self-hosted Runner \n앞서 말씀드린 파이프라인 대로 배포를 하기 위해서는, 배포를 할 서버에 `GitHub Actions`의 `Self-hosted Runner`를 설치해야 합니다.  \n\n앞서 설명드린 `workflow`는 GitHub에서 호스팅하는 Runner가 수행할 수도 있지만,  \n원하는 서버에 자체적으로 Runner를 호스팅하여 사용할 수도 있습니다.\n\nworkflow의 `runs-on` 블록에서 어떤 Runner를 통해 작업을 수행할지 정의합니다.\n\n\n\n### EC2에 Self-hosted Runner 띄우기\n\n#### 1. 다운로드  \n레포지토리의 `Settings` - `Actions` - `Runners`에 들어가면 `New self-hosted runner` 버튼이 있습니다.  \n![create-runner.png](.index_image/create-runner.png)\n버튼을 누르면 아래와 같은 설정 페이지로 접속하는데, Runner를 띄울 서버 환경에 맞는 설정을 선택해줍니다.  \n   ![architecture-runner.png](.index_image/architecture-runner.png)\n해당 환경의 터미널에서 runner package를 다운로드합니다. 선택한 설정에 맞게 제공된 커맨드를 복사해 실행하면 됩니다.  \n   ![download-runner.png](.index_image/download-runner.png)   \n\n아래는 Linux, ARM64 환경의 runner를 다운로드받기 위한 스크립트입니다.  \n  ```shell\n  # Create a folder\n  $ mkdir actions-runner && cd actions-runner\n  # Download the latest runner package\n  $ curl -o actions-runner-linux-arm64-2.307.1.tar.gz -L https://github.com/actions/runner/releases/download/v2.307.1/actions-runner-linux-arm64-2.307.1.tar.gz\n  # Optional: Validate the hash\n  $ echo \"01edc84342ef4128a8f19bc2f33709b40f2f1c40e250e2a4c5e0adf620044ab3  actions-runner-linux-arm64-2.307.1.tar.gz\" | shasum -a 256 -c\n  # Extract the installer\n  $ tar xzf ./actions-runner-linux-arm64-2.307.1.tar.gz\n  ```\n   \n#### 2. Runner 생성 및 설정\n마찬가지로 제공된 스크립트에 따라, runner를 생성하고 설정합니다.  \n![configure-runner.png](.index_image/configure-runner.png)\n먼저 아래 커맨드를 실행하면, 아래와 같이 Runner 환경 설정을 위해 몇 가지를 입력해야 합니다.  \n```shell\n$ ./config.sh --url ${repository URL} --token ${runner 생성 페이지에서 제공된 토큰}\n```\n![runner-registration.png](.index_image/runner-registration.png)\n\n위 이미지처럼 name, 추가 label을 지정하고 설치한 runner를 확인하면, 다음과 같이 `dev` 라벨이 추가된 것을 확인할 수 있습니다.\n![runner-label.png](.index_image/runner-label.png)\n> ⚠️ 개인 로컬에서 테스트로 만든 예시 이미지로, 실제 서비스의 운영 환경과는 상이합니다.\n\n더 빠른 설정을 원한다면, 아래와 같이 `./config.sh` 실행 시 원하는 값들을 바로 전달해줘도 됩니다.\n```shell\n$ ./config.sh --url ${repository URL} --token ${runner 생성 페이지에서 제공된 토큰} --name test --labels dev\n```\n\n   > **label을 왜 추가했을까요?**    \n   각 Runner를 구분할 수 있는 label을 지정해서 `runs-on` 블록에서 어떤 Runner에게 일을 시킬지 명시하기 위함입니다.  \n   괜찮을지도 팀은 한 리포지토리에서 운영 서버, 개발 서버에 각각 띄울 두 개의 Runner를 사용하기 때문에\n   이를 구분하기 위한 `dev`, `prod` label을 지정하였습니다.  \n   아래는 `dev`, `self-hosted` 라벨을 가진 runner를 지정하는 예시입니다.\n   ```YAML\n   runs-on: [ self-hosted, dev ]\n   ```\n   > **이미 생성한 Runner에 label을 추가하려면?**  \n   GitHub 공식문서에 따르면, 2023년 2월부터 GUI로 label을 추가하는 기능을 제공하지 않는다고 합니다.    \n   config.sh 파일을 수정해 설정할 수도 없습니다.    \n   대신 GitHub에서 제공하는 \"Self-hosted runners\" REST API를 사용해 추가해주어야 합니다.\n\n#### 3. Runner 실행\n   Runner 설정이 완료되었다면, 아래 명령어로 Runner를 실행합니다.  \n   레포지토리의 `Settings` - `Actions` - `Runners` 페이지에서 Status가 `idle`로 바뀌었다면 정상적으로 실행된 것입니다.\n   ```shell\n   $ ./run.sh\n   ```\n\n참고로 서버 내 저장한 환경변수를 업데이트 했을 때에는, Runner도 재시작하기를 잊지 마세요!  \n왜일까요? 자세한 내용은  \n[EC2 환경 변수 적용 및 Actions Runner에 환경 변수 적용이 안되는 이슈](https://map-befine-official.github.io/trouble-shooting-actions-runner)에서 확인하실 수 있습니다.\n\n\n## 참고 자료\nhttps://docs.github.com/ko/actions/using-workflows/about-workflows  \nhttps://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners/about-self-hosted-runners  \nhttps://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners/using-labels-with-self-hosted-runners  \n"},{"excerpt":"이 글은 우테코 괜찮을지도팀의 가 작성했습니다. 첫 글은 포스트 작성법에 대해서 다루어보도록 하겠습니다. Repository Local 로 Clone 해오기 본인이 원하는 Directory 로 이동해  위와 같은 명령어를 이용하여 우리 팀의 Repository 를 Local 로 가져옵니다. 글 작성하기 Repository 를 Local 로 가져오셨다면, …","fields":{"slug":"/how-to-write-a-post/"},"frontmatter":{"date":"July 24, 2023","title":"포스트 작성 방법","tags":["블로그"]},"rawMarkdownBody":"\n> 이 글은 우테코 괜찮을지도팀의 `매튜`가 작성했습니다.\n\n첫 글은 포스트 작성법에 대해서 다루어보도록 하겠습니다.\n\n### Repository Local 로 Clone 해오기 \n\n본인이 원하는 Directory 로 이동해 \n\n```shell\ngit clone https://github.com/map-befine-official/map-befine-official.github.io \n``` \n\n위와 같은 명령어를 이용하여 우리 팀의 Repository 를 Local 로 가져옵니다.\n\n## 글 작성하기\n\nRepository 를 Local 로 가져오셨다면, 이제 글을 작성해봅시다!\n\n```shell\ncd map-befine-official.github.io\n```\n\n위 명령어를 통해서 map-befine-official.github.io 에 Directory 에 들어가주시면 Contents Directory 가 보이실 겁니다.\n\n여기서 \n\n```shell\ncd contents/posts\n```\n\n위 명령어를 통해 contents/posts 디렉토리 내부까지 가고\n\n본인이 작성하고자 하는 주제에 걸맞는 이름으로 Directory 를 생성한 후, 만드신 Directory까지 들어가주세요\n\n저 같은 경우는 Directory 명을 how-to-write-a-post 로 지었기 때문에\n\n```shell\ncd how-to-write-a-post\n```\n\n위와 같은 명령어를 통해 이동 해주었습니다.\n\n![](.index_image/command.png)\n\n여기서부터 이제 `index.md` 파일을 만들어 작성하실 글을 Markdown 형식으로 작성 해주시면되고, `.index_image` 라는 이름으로 Directory 만들어 해당 Directory 에 이미지 파일을 넣어주시면 됩니다.\n\n잘 따라오셨다면 최종적으로 이런 구조가 나올겁니다!\n\n![](.index_image/directory_structure.png)\n\n## 글 올리기!\n\n글을 모두 작성하셨다면 이제 올리기만 하면 될 겁니다.\n\n아주 쉽습니다.\n\n그냥 main 브랜치에 push 를 하시면돼요!\n\n`.github/workflows/deploy.yml` 로 인해서 push 만 하셔도 배포 될겁니다.\n\n야물딱지죠?\n\n우리 글도 한번 야무지게 써봅시다!\n\n## 글의 제목 작성하기\n\n글의 서두에 \n\n```text\n---\ntitle: \"제목\"\ndescription: \"설명\"\ndate: \"작성 날짜\"\nupdate: \"수정 날짜\"\ntags:\n  - 태그들\n  - ...\n---\n```\n\n이런 식으로 작성해주셔야지 \n\n![](.index_image/title.png)\n\n위에서 보시는 바와 같이 하실 수 있습니다.\n\n## 이미지 삽입\n\n이미지를 삽입하시고 싶으시다면, \n\n저의 가이드를 모두 잘 따르셨다고 가정했을 때, .index_image 내부에 image 파일을 넣고\n\n```text\n![](.index_image/{이미지 파일 명})\n```\n\n이런 식으로 작성해주시면 이미지도 정상적으로 삽입하실  수 있습니다!\n\n## 주의!\n\n다른 사람들의 정성스런 글을 날리지 않기 위해, 항상 Push 이전에 Pull 해주는 거 잊지 않으셨죠? ㅋㅋㅋ\n\n물론 Warning Message 가 뜨긴 할테지만, 잊지 말아주세용~~~\n\n## 레퍼런스 \n\nhttps://pium-official.github.io/blog-starter/\n\n\n"}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}